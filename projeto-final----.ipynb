{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># **Ciência dos Dados** <font color=purple>- Projeto 3</font>\n",
    "   #### <font color=grey> <p>Gianlucca de La Torre Napolitano </p> <p>Lucas Nicascio dos Santos</p> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação do peso de características a serem destacadas na fabricação da maconha e seus impactos na avaliação final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O projeto visa a análise de características presentes na Maconha como seus efeitos, sabor e tipo de forma a prever quais os fatores devem ser mais focados na fabricação de forma a obter uma ótima avaliação pelo público, tendo em vista que as características podem ser ajustadas pelas proporções de THC (Tetrahidrocanabinol) e CBD (Canabidiol) (não aprofundados nesse projeto) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente é necessário ler o Dataset \"Cannabis Strains\" obtido na plataforma Kaggle, bem como criar um Data Frame ábil para análise, pois contém variáveis qualitativas e quantitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import beta, probplot\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos arquivos em .csv e eliminação dos valores nulos do DataFrame \n",
    "df = pd.read_csv('cannabis.csv')\n",
    "data = df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação dos valores em \"Type\" em colunas de 0 e 1 para equivalência de variáveis qualitativas em quantitativas\n",
    "tipo = data['Type'].str.get_dummies(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Effects\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "efeitos = data['Effects'].str.get_dummies(sep=',')\n",
    "efeitos = efeitos.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "data_nova = data.join(efeitos, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Flavours\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "sabores = data['Flavor'].str.get_dummies(sep=',')\n",
    "sabores = sabores.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "datanova = data_nova.join(sabores, how = 'inner')\n",
    "datanova0 = datanova.join(tipo,how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de colunas não mais necessárias do DataFrame\n",
    "datanova1 = datanova0.drop(['Effects','Flavor','Type','Strain','Description'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rating', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
       "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
       "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
       "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
       "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
       "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
       "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
       "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
       "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
       "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody', 'hybrid', 'indica',\n",
       "       'sativa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanova1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress1(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinação das variáveis a serem utilizadas na regressão. A variável x foi separada de duas formas para testarmos a hipótese de que os sabores podem não ter um efeito significativo na regressão, pois são avaliados de forma subjetiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['hybrid', 'indica',\n",
    "       'sativa', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n",
    "X = datanova1[['Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.427</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>5.39e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:39:30</td>     <th>  Log-Likelihood:    </th> <td> -2115.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4361.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2212</td>      <th>  BIC:               </th> <td>   4734.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    64</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    1.2760</td> <td>    0.049</td> <td>   26.100</td> <td> 0.000</td> <td>    1.180</td> <td>    1.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hybrid</th>       <td>    0.4227</td> <td>    0.023</td> <td>   18.105</td> <td> 0.000</td> <td>    0.377</td> <td>    0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indica</th>       <td>    0.4274</td> <td>    0.030</td> <td>   14.066</td> <td> 0.000</td> <td>    0.368</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sativa</th>       <td>    0.4259</td> <td>    0.032</td> <td>   13.345</td> <td> 0.000</td> <td>    0.363</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.4590</td> <td>    0.051</td> <td>    8.927</td> <td> 0.000</td> <td>    0.358</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.4618</td> <td>    0.036</td> <td>   13.004</td> <td> 0.000</td> <td>    0.392</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.0586</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.4496</td> <td>    0.039</td> <td>   11.409</td> <td> 0.000</td> <td>    0.372</td> <td>    0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.4445</td> <td>    0.036</td> <td>   12.420</td> <td> 0.000</td> <td>    0.374</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.4287</td> <td>    0.037</td> <td>   11.612</td> <td> 0.000</td> <td>    0.356</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.3654</td> <td>    0.045</td> <td>    8.063</td> <td> 0.000</td> <td>    0.277</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.4259</td> <td>    0.040</td> <td>   10.635</td> <td> 0.000</td> <td>    0.347</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.3727</td> <td>    0.040</td> <td>    9.315</td> <td> 0.000</td> <td>    0.294</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.0586</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.5689</td> <td>    0.041</td> <td>   13.859</td> <td> 0.000</td> <td>    0.488</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.4113</td> <td>    0.040</td> <td>   10.269</td> <td> 0.000</td> <td>    0.333</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.4532</td> <td>    0.043</td> <td>   10.644</td> <td> 0.000</td> <td>    0.370</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.3967</td> <td>    0.042</td> <td>    9.356</td> <td> 0.000</td> <td>    0.314</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.4258</td> <td>    0.035</td> <td>   12.047</td> <td> 0.000</td> <td>    0.356</td> <td>    0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2173</td> <td>    0.125</td> <td>    1.738</td> <td> 0.082</td> <td>   -0.028</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>   -0.0945</td> <td>    0.164</td> <td>   -0.577</td> <td> 0.564</td> <td>   -0.416</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.1057</td> <td>    0.225</td> <td>    0.470</td> <td> 0.639</td> <td>   -0.336</td> <td>    0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2101</td> <td>    0.049</td> <td>    4.274</td> <td> 0.000</td> <td>    0.114</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1264</td> <td>    0.227</td> <td>   -0.558</td> <td> 0.577</td> <td>   -0.571</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.1744</td> <td>    0.065</td> <td>    2.667</td> <td> 0.008</td> <td>    0.046</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.0979</td> <td>    0.149</td> <td>    0.658</td> <td> 0.510</td> <td>   -0.194</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0446</td> <td>    0.092</td> <td>    0.484</td> <td> 0.628</td> <td>   -0.136</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.1902</td> <td>    0.110</td> <td>    1.727</td> <td> 0.084</td> <td>   -0.026</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.0416</td> <td>    0.261</td> <td>    0.159</td> <td> 0.874</td> <td>   -0.471</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.1617</td> <td>    0.045</td> <td>    3.556</td> <td> 0.000</td> <td>    0.073</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.2958</td> <td>    0.134</td> <td>    2.207</td> <td> 0.027</td> <td>    0.033</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.1600</td> <td>    0.053</td> <td>    3.038</td> <td> 0.002</td> <td>    0.057</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1425</td> <td>    0.041</td> <td>    3.495</td> <td> 0.000</td> <td>    0.063</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2043</td> <td>    0.051</td> <td>    4.012</td> <td> 0.000</td> <td>    0.104</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.1928</td> <td>    0.067</td> <td>    2.876</td> <td> 0.004</td> <td>    0.061</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1318</td> <td>    0.108</td> <td>    1.217</td> <td> 0.224</td> <td>   -0.081</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2269</td> <td>    0.118</td> <td>    1.924</td> <td> 0.055</td> <td>   -0.004</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.1748</td> <td>    0.110</td> <td>    1.587</td> <td> 0.113</td> <td>   -0.041</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.1698</td> <td>    0.057</td> <td>    2.966</td> <td> 0.003</td> <td>    0.058</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2569</td> <td>    0.094</td> <td>    2.746</td> <td> 0.006</td> <td>    0.073</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1520</td> <td>    0.116</td> <td>    1.314</td> <td> 0.189</td> <td>   -0.075</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.3414</td> <td>    0.138</td> <td>    2.474</td> <td> 0.013</td> <td>    0.071</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.1778</td> <td>    0.154</td> <td>    1.154</td> <td> 0.249</td> <td>   -0.124</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3269</td> <td>    0.105</td> <td>    3.110</td> <td> 0.002</td> <td>    0.121</td> <td>    0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.1307</td> <td>    0.130</td> <td>    1.005</td> <td> 0.315</td> <td>   -0.124</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.1756</td> <td>    0.082</td> <td>    2.153</td> <td> 0.031</td> <td>    0.016</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.4750</td> <td>    0.259</td> <td>    1.835</td> <td> 0.067</td> <td>   -0.033</td> <td>    0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2176</td> <td>    0.367</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.501</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.1970</td> <td>    0.089</td> <td>    2.216</td> <td> 0.027</td> <td>    0.023</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.1902</td> <td>    0.050</td> <td>    3.774</td> <td> 0.000</td> <td>    0.091</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.1847</td> <td>    0.106</td> <td>    1.745</td> <td> 0.081</td> <td>   -0.023</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0256</td> <td>    0.447</td> <td>    0.057</td> <td> 0.954</td> <td>   -0.851</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.1642</td> <td>    0.046</td> <td>    3.607</td> <td> 0.000</td> <td>    0.075</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1002</td> <td>    0.162</td> <td>    0.619</td> <td> 0.536</td> <td>   -0.217</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.1884</td> <td>    0.107</td> <td>    1.768</td> <td> 0.077</td> <td>   -0.021</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.1866</td> <td>    0.059</td> <td>    3.152</td> <td> 0.002</td> <td>    0.071</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2020</td> <td>    0.053</td> <td>    3.788</td> <td> 0.000</td> <td>    0.097</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1300</td> <td>    0.098</td> <td>    1.326</td> <td> 0.185</td> <td>   -0.062</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.1798</td> <td>    0.040</td> <td>    4.484</td> <td> 0.000</td> <td>    0.101</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.2833</td> <td>    0.239</td> <td>    1.183</td> <td> 0.237</td> <td>   -0.186</td> <td>    0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0563</td> <td>    0.155</td> <td>    0.362</td> <td> 0.717</td> <td>   -0.249</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0468</td> <td>    0.225</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.487</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.1833</td> <td>    0.063</td> <td>    2.922</td> <td> 0.004</td> <td>    0.060</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1465</td> <td>    0.117</td> <td>    1.249</td> <td> 0.212</td> <td>   -0.084</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.1790</td> <td>    0.242</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.295</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.0860</td> <td>    0.053</td> <td>    1.631</td> <td> 0.103</td> <td>   -0.017</td> <td>    0.189</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>557.494</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18579.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.454</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.965</td>  <th>  Cond. No.          </th> <td>1.15e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.443\n",
       "Model:                            OLS   Adj. R-squared:                  0.427\n",
       "Method:                 Least Squares   F-statistic:                     27.47\n",
       "Date:                Mon, 19 Nov 2018   Prob (F-statistic):          5.39e-232\n",
       "Time:                        18:39:30   Log-Likelihood:                -2115.6\n",
       "No. Observations:                2277   AIC:                             4361.\n",
       "Df Residuals:                    2212   BIC:                             4734.\n",
       "Df Model:                          64                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            1.2760      0.049     26.100      0.000       1.180       1.372\n",
       "hybrid           0.4227      0.023     18.105      0.000       0.377       0.468\n",
       "indica           0.4274      0.030     14.066      0.000       0.368       0.487\n",
       "sativa           0.4259      0.032     13.345      0.000       0.363       0.489\n",
       "Aroused          0.4590      0.051      8.927      0.000       0.358       0.560\n",
       "Creative         0.4618      0.036     13.004      0.000       0.392       0.531\n",
       "Dry              1.0586      0.340      3.116      0.002       0.392       1.725\n",
       "Energetic        0.4496      0.039     11.409      0.000       0.372       0.527\n",
       "Euphoric         0.4445      0.036     12.420      0.000       0.374       0.515\n",
       "Focused          0.4287      0.037     11.612      0.000       0.356       0.501\n",
       "Giggly           0.3654      0.045      8.063      0.000       0.277       0.454\n",
       "Happy            0.4259      0.040     10.635      0.000       0.347       0.504\n",
       "Hungry           0.3727      0.040      9.315      0.000       0.294       0.451\n",
       "Mouth            1.0586      0.340      3.116      0.002       0.392       1.725\n",
       "Relaxed          0.5689      0.041     13.859      0.000       0.488       0.649\n",
       "Sleepy           0.4113      0.040     10.269      0.000       0.333       0.490\n",
       "Talkative        0.4532      0.043     10.644      0.000       0.370       0.537\n",
       "Tingly           0.3967      0.042      9.356      0.000       0.314       0.480\n",
       "Uplifted         0.4258      0.035     12.047      0.000       0.356       0.495\n",
       "Ammonia          0.2173      0.125      1.738      0.082      -0.028       0.462\n",
       "Apple           -0.0945      0.164     -0.577      0.564      -0.416       0.227\n",
       "Apricot          0.1057      0.225      0.470      0.639      -0.336       0.547\n",
       "Berry            0.2101      0.049      4.274      0.000       0.114       0.306\n",
       "Blue            -0.1264      0.227     -0.558      0.577      -0.571       0.318\n",
       "Blueberry        0.1744      0.065      2.667      0.008       0.046       0.303\n",
       "Butter           0.0979      0.149      0.658      0.510      -0.194       0.389\n",
       "Cheese           0.0446      0.092      0.484      0.628      -0.136       0.225\n",
       "Chemical         0.1902      0.110      1.727      0.084      -0.026       0.406\n",
       "Chestnut         0.0416      0.261      0.159      0.874      -0.471       0.554\n",
       "Citrus           0.1617      0.045      3.556      0.000       0.073       0.251\n",
       "Coffee           0.2958      0.134      2.207      0.027       0.033       0.559\n",
       "Diesel           0.1600      0.053      3.038      0.002       0.057       0.263\n",
       "Earthy           0.1425      0.041      3.495      0.000       0.063       0.223\n",
       "Flowery          0.2043      0.051      4.012      0.000       0.104       0.304\n",
       "Fruit            0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Grape            0.1928      0.067      2.876      0.004       0.061       0.324\n",
       "Grapefruit       0.1318      0.108      1.217      0.224      -0.081       0.344\n",
       "Honey            0.2269      0.118      1.924      0.055      -0.004       0.458\n",
       "Lavender         0.1748      0.110      1.587      0.113      -0.041       0.391\n",
       "Lemon            0.1698      0.057      2.966      0.003       0.058       0.282\n",
       "Lime             0.2569      0.094      2.746      0.006       0.073       0.440\n",
       "Mango            0.1520      0.116      1.314      0.189      -0.075       0.379\n",
       "Menthol          0.3414      0.138      2.474      0.013       0.071       0.612\n",
       "Mint             0.1778      0.154      1.154      0.249      -0.124       0.480\n",
       "Minty            0.3269      0.105      3.110      0.002       0.121       0.533\n",
       "Nutty            0.1307      0.130      1.005      0.315      -0.124       0.386\n",
       "Orange           0.1756      0.082      2.153      0.031       0.016       0.336\n",
       "Peach            0.4750      0.259      1.835      0.067      -0.033       0.983\n",
       "Pear             0.2176      0.367      0.594      0.553      -0.501       0.936\n",
       "Pepper           0.1970      0.089      2.216      0.027       0.023       0.371\n",
       "Pine             0.1902      0.050      3.774      0.000       0.091       0.289\n",
       "Pineapple        0.1847      0.106      1.745      0.081      -0.023       0.392\n",
       "Plum             0.0256      0.447      0.057      0.954      -0.851       0.903\n",
       "Pungent          0.1642      0.046      3.607      0.000       0.075       0.253\n",
       "Rose             0.1002      0.162      0.619      0.536      -0.217       0.418\n",
       "Sage             0.1884      0.107      1.768      0.077      -0.021       0.397\n",
       "Skunk            0.1866      0.059      3.152      0.002       0.071       0.303\n",
       "Spicy/Herbal     0.2020      0.053      3.788      0.000       0.097       0.307\n",
       "Strawberry       0.1300      0.098      1.326      0.185      -0.062       0.322\n",
       "Sweet            0.1798      0.040      4.484      0.000       0.101       0.258\n",
       "Tar              0.2833      0.239      1.183      0.237      -0.186       0.753\n",
       "Tea              0.0563      0.155      0.362      0.717      -0.249       0.361\n",
       "Tobacco         -0.0468      0.225     -0.208      0.835      -0.487       0.394\n",
       "Tree             0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Tropical         0.1833      0.063      2.922      0.004       0.060       0.306\n",
       "Vanilla          0.1465      0.117      1.249      0.212      -0.084       0.377\n",
       "Violet           0.1790      0.242      0.741      0.459      -0.295       0.653\n",
       "Woody            0.0860      0.053      1.631      0.103      -0.017       0.189\n",
       "==============================================================================\n",
       "Omnibus:                      557.494   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18579.690\n",
       "Skew:                          -0.454   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.965   Cond. No.                     1.15e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.14e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress1(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.428</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   121.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>5.90e-262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:39:30</td>     <th>  Log-Likelihood:    </th> <td> -2145.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4320.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2262</td>      <th>  BIC:               </th> <td>   4406.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    1.7278</td> <td>    0.065</td> <td>   26.705</td> <td> 0.000</td> <td>    1.601</td> <td>    1.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.5517</td> <td>    0.048</td> <td>   11.465</td> <td> 0.000</td> <td>    0.457</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.5517</td> <td>    0.031</td> <td>   17.939</td> <td> 0.000</td> <td>    0.491</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.2722</td> <td>    0.626</td> <td>    3.629</td> <td> 0.000</td> <td>    1.044</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.5412</td> <td>    0.034</td> <td>   15.845</td> <td> 0.000</td> <td>    0.474</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.5400</td> <td>    0.031</td> <td>   17.683</td> <td> 0.000</td> <td>    0.480</td> <td>    0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.5161</td> <td>    0.032</td> <td>   16.031</td> <td> 0.000</td> <td>    0.453</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.4525</td> <td>    0.042</td> <td>   10.764</td> <td> 0.000</td> <td>    0.370</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.5248</td> <td>    0.035</td> <td>   15.106</td> <td> 0.000</td> <td>    0.457</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.4509</td> <td>    0.036</td> <td>   12.514</td> <td> 0.000</td> <td>    0.380</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    0.6743</td> <td>    0.035</td> <td>   19.396</td> <td> 0.000</td> <td>    0.606</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.4967</td> <td>    0.033</td> <td>   14.862</td> <td> 0.000</td> <td>    0.431</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.5547</td> <td>    0.038</td> <td>   14.446</td> <td> 0.000</td> <td>    0.479</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.4803</td> <td>    0.039</td> <td>   12.395</td> <td> 0.000</td> <td>    0.404</td> <td>    0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.5156</td> <td>    0.030</td> <td>   17.043</td> <td> 0.000</td> <td>    0.456</td> <td>    0.575</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>621.229</td> <th>  Durbin-Watson:     </th> <td>   1.939</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20884.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.611</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>17.786</td>  <th>  Cond. No.          </th> <td>    92.0</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.428\n",
       "Model:                            OLS   Adj. R-squared:                  0.425\n",
       "Method:                 Least Squares   F-statistic:                     121.0\n",
       "Date:                Mon, 19 Nov 2018   Prob (F-statistic):          5.90e-262\n",
       "Time:                        18:39:30   Log-Likelihood:                -2145.2\n",
       "No. Observations:                2277   AIC:                             4320.\n",
       "Df Residuals:                    2262   BIC:                             4406.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.7278      0.065     26.705      0.000       1.601       1.855\n",
       "Aroused        0.5517      0.048     11.465      0.000       0.457       0.646\n",
       "Creative       0.5517      0.031     17.939      0.000       0.491       0.612\n",
       "Dry            2.2722      0.626      3.629      0.000       1.044       3.500\n",
       "Energetic      0.5412      0.034     15.845      0.000       0.474       0.608\n",
       "Euphoric       0.5400      0.031     17.683      0.000       0.480       0.600\n",
       "Focused        0.5161      0.032     16.031      0.000       0.453       0.579\n",
       "Giggly         0.4525      0.042     10.764      0.000       0.370       0.535\n",
       "Happy          0.5248      0.035     15.106      0.000       0.457       0.593\n",
       "Hungry         0.4509      0.036     12.514      0.000       0.380       0.522\n",
       "Relaxed        0.6743      0.035     19.396      0.000       0.606       0.742\n",
       "Sleepy         0.4967      0.033     14.862      0.000       0.431       0.562\n",
       "Talkative      0.5547      0.038     14.446      0.000       0.479       0.630\n",
       "Tingly         0.4803      0.039     12.395      0.000       0.404       0.556\n",
       "Uplifted       0.5156      0.030     17.043      0.000       0.456       0.575\n",
       "==============================================================================\n",
       "Omnibus:                      621.229   Durbin-Watson:                   1.939\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20884.032\n",
       "Skew:                          -0.611   Prob(JB):                         0.00\n",
       "Kurtosis:                      17.786   Cond. No.                         92.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto (sabores)\n",
    "results = regress1(X,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos realizadas as regressoes, foi observado que o valor de R^2 estava baixo. eliminando as variaveis com valores \"p\" alto, continuou um valor baixo para R^2. Entao, foi retirado da regressao a constante os o resultados estao mostrados a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressao sem a constante\n",
    "def regress(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['hybrid', 'indica',\n",
    "       'sativa', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.427</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>5.39e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:39:31</td>     <th>  Log-Likelihood:    </th> <td> -2115.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4361.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2212</td>      <th>  BIC:               </th> <td>   4734.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    64</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hybrid</th>       <td>    1.6987</td> <td>    0.066</td> <td>   25.816</td> <td> 0.000</td> <td>    1.570</td> <td>    1.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indica</th>       <td>    1.7034</td> <td>    0.071</td> <td>   24.126</td> <td> 0.000</td> <td>    1.565</td> <td>    1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sativa</th>       <td>    1.7019</td> <td>    0.072</td> <td>   23.777</td> <td> 0.000</td> <td>    1.562</td> <td>    1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.4590</td> <td>    0.051</td> <td>    8.927</td> <td> 0.000</td> <td>    0.358</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.4618</td> <td>    0.036</td> <td>   13.004</td> <td> 0.000</td> <td>    0.392</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.0586</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.4496</td> <td>    0.039</td> <td>   11.409</td> <td> 0.000</td> <td>    0.372</td> <td>    0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.4445</td> <td>    0.036</td> <td>   12.420</td> <td> 0.000</td> <td>    0.374</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.4287</td> <td>    0.037</td> <td>   11.612</td> <td> 0.000</td> <td>    0.356</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.3654</td> <td>    0.045</td> <td>    8.063</td> <td> 0.000</td> <td>    0.277</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.4259</td> <td>    0.040</td> <td>   10.635</td> <td> 0.000</td> <td>    0.347</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.3727</td> <td>    0.040</td> <td>    9.315</td> <td> 0.000</td> <td>    0.294</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.0586</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.5689</td> <td>    0.041</td> <td>   13.859</td> <td> 0.000</td> <td>    0.488</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.4113</td> <td>    0.040</td> <td>   10.269</td> <td> 0.000</td> <td>    0.333</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.4532</td> <td>    0.043</td> <td>   10.644</td> <td> 0.000</td> <td>    0.370</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.3967</td> <td>    0.042</td> <td>    9.356</td> <td> 0.000</td> <td>    0.314</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.4258</td> <td>    0.035</td> <td>   12.047</td> <td> 0.000</td> <td>    0.356</td> <td>    0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2173</td> <td>    0.125</td> <td>    1.738</td> <td> 0.082</td> <td>   -0.028</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>   -0.0945</td> <td>    0.164</td> <td>   -0.577</td> <td> 0.564</td> <td>   -0.416</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.1057</td> <td>    0.225</td> <td>    0.470</td> <td> 0.639</td> <td>   -0.336</td> <td>    0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2101</td> <td>    0.049</td> <td>    4.274</td> <td> 0.000</td> <td>    0.114</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1264</td> <td>    0.227</td> <td>   -0.558</td> <td> 0.577</td> <td>   -0.571</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.1744</td> <td>    0.065</td> <td>    2.667</td> <td> 0.008</td> <td>    0.046</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.0979</td> <td>    0.149</td> <td>    0.658</td> <td> 0.510</td> <td>   -0.194</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0446</td> <td>    0.092</td> <td>    0.484</td> <td> 0.628</td> <td>   -0.136</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.1902</td> <td>    0.110</td> <td>    1.727</td> <td> 0.084</td> <td>   -0.026</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.0416</td> <td>    0.261</td> <td>    0.159</td> <td> 0.874</td> <td>   -0.471</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.1617</td> <td>    0.045</td> <td>    3.556</td> <td> 0.000</td> <td>    0.073</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.2958</td> <td>    0.134</td> <td>    2.207</td> <td> 0.027</td> <td>    0.033</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.1600</td> <td>    0.053</td> <td>    3.038</td> <td> 0.002</td> <td>    0.057</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1425</td> <td>    0.041</td> <td>    3.495</td> <td> 0.000</td> <td>    0.063</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2043</td> <td>    0.051</td> <td>    4.012</td> <td> 0.000</td> <td>    0.104</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.1928</td> <td>    0.067</td> <td>    2.876</td> <td> 0.004</td> <td>    0.061</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1318</td> <td>    0.108</td> <td>    1.217</td> <td> 0.224</td> <td>   -0.081</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2269</td> <td>    0.118</td> <td>    1.924</td> <td> 0.055</td> <td>   -0.004</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.1748</td> <td>    0.110</td> <td>    1.587</td> <td> 0.113</td> <td>   -0.041</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.1698</td> <td>    0.057</td> <td>    2.966</td> <td> 0.003</td> <td>    0.058</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2569</td> <td>    0.094</td> <td>    2.746</td> <td> 0.006</td> <td>    0.073</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1520</td> <td>    0.116</td> <td>    1.314</td> <td> 0.189</td> <td>   -0.075</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.3414</td> <td>    0.138</td> <td>    2.474</td> <td> 0.013</td> <td>    0.071</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.1778</td> <td>    0.154</td> <td>    1.154</td> <td> 0.249</td> <td>   -0.124</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3269</td> <td>    0.105</td> <td>    3.110</td> <td> 0.002</td> <td>    0.121</td> <td>    0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.1307</td> <td>    0.130</td> <td>    1.005</td> <td> 0.315</td> <td>   -0.124</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.1756</td> <td>    0.082</td> <td>    2.153</td> <td> 0.031</td> <td>    0.016</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.4750</td> <td>    0.259</td> <td>    1.835</td> <td> 0.067</td> <td>   -0.033</td> <td>    0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2176</td> <td>    0.367</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.501</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.1970</td> <td>    0.089</td> <td>    2.216</td> <td> 0.027</td> <td>    0.023</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.1902</td> <td>    0.050</td> <td>    3.774</td> <td> 0.000</td> <td>    0.091</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.1847</td> <td>    0.106</td> <td>    1.745</td> <td> 0.081</td> <td>   -0.023</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0256</td> <td>    0.447</td> <td>    0.057</td> <td> 0.954</td> <td>   -0.851</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.1642</td> <td>    0.046</td> <td>    3.607</td> <td> 0.000</td> <td>    0.075</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1002</td> <td>    0.162</td> <td>    0.619</td> <td> 0.536</td> <td>   -0.217</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.1884</td> <td>    0.107</td> <td>    1.768</td> <td> 0.077</td> <td>   -0.021</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.1866</td> <td>    0.059</td> <td>    3.152</td> <td> 0.002</td> <td>    0.071</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2020</td> <td>    0.053</td> <td>    3.788</td> <td> 0.000</td> <td>    0.097</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1300</td> <td>    0.098</td> <td>    1.326</td> <td> 0.185</td> <td>   -0.062</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.1798</td> <td>    0.040</td> <td>    4.484</td> <td> 0.000</td> <td>    0.101</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.2833</td> <td>    0.239</td> <td>    1.183</td> <td> 0.237</td> <td>   -0.186</td> <td>    0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0563</td> <td>    0.155</td> <td>    0.362</td> <td> 0.717</td> <td>   -0.249</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0468</td> <td>    0.225</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.487</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.1833</td> <td>    0.063</td> <td>    2.922</td> <td> 0.004</td> <td>    0.060</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1465</td> <td>    0.117</td> <td>    1.249</td> <td> 0.212</td> <td>   -0.084</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.1790</td> <td>    0.242</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.295</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.0860</td> <td>    0.053</td> <td>    1.631</td> <td> 0.103</td> <td>   -0.017</td> <td>    0.189</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>557.494</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18579.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.454</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.965</td>  <th>  Cond. No.          </th> <td>1.48e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.443\n",
       "Model:                            OLS   Adj. R-squared:                  0.427\n",
       "Method:                 Least Squares   F-statistic:                     27.47\n",
       "Date:                Mon, 19 Nov 2018   Prob (F-statistic):          5.39e-232\n",
       "Time:                        18:39:31   Log-Likelihood:                -2115.6\n",
       "No. Observations:                2277   AIC:                             4361.\n",
       "Df Residuals:                    2212   BIC:                             4734.\n",
       "Df Model:                          64                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "hybrid           1.6987      0.066     25.816      0.000       1.570       1.828\n",
       "indica           1.7034      0.071     24.126      0.000       1.565       1.842\n",
       "sativa           1.7019      0.072     23.777      0.000       1.562       1.842\n",
       "Aroused          0.4590      0.051      8.927      0.000       0.358       0.560\n",
       "Creative         0.4618      0.036     13.004      0.000       0.392       0.531\n",
       "Dry              1.0586      0.340      3.116      0.002       0.392       1.725\n",
       "Energetic        0.4496      0.039     11.409      0.000       0.372       0.527\n",
       "Euphoric         0.4445      0.036     12.420      0.000       0.374       0.515\n",
       "Focused          0.4287      0.037     11.612      0.000       0.356       0.501\n",
       "Giggly           0.3654      0.045      8.063      0.000       0.277       0.454\n",
       "Happy            0.4259      0.040     10.635      0.000       0.347       0.504\n",
       "Hungry           0.3727      0.040      9.315      0.000       0.294       0.451\n",
       "Mouth            1.0586      0.340      3.116      0.002       0.392       1.725\n",
       "Relaxed          0.5689      0.041     13.859      0.000       0.488       0.649\n",
       "Sleepy           0.4113      0.040     10.269      0.000       0.333       0.490\n",
       "Talkative        0.4532      0.043     10.644      0.000       0.370       0.537\n",
       "Tingly           0.3967      0.042      9.356      0.000       0.314       0.480\n",
       "Uplifted         0.4258      0.035     12.047      0.000       0.356       0.495\n",
       "Ammonia          0.2173      0.125      1.738      0.082      -0.028       0.462\n",
       "Apple           -0.0945      0.164     -0.577      0.564      -0.416       0.227\n",
       "Apricot          0.1057      0.225      0.470      0.639      -0.336       0.547\n",
       "Berry            0.2101      0.049      4.274      0.000       0.114       0.306\n",
       "Blue            -0.1264      0.227     -0.558      0.577      -0.571       0.318\n",
       "Blueberry        0.1744      0.065      2.667      0.008       0.046       0.303\n",
       "Butter           0.0979      0.149      0.658      0.510      -0.194       0.389\n",
       "Cheese           0.0446      0.092      0.484      0.628      -0.136       0.225\n",
       "Chemical         0.1902      0.110      1.727      0.084      -0.026       0.406\n",
       "Chestnut         0.0416      0.261      0.159      0.874      -0.471       0.554\n",
       "Citrus           0.1617      0.045      3.556      0.000       0.073       0.251\n",
       "Coffee           0.2958      0.134      2.207      0.027       0.033       0.559\n",
       "Diesel           0.1600      0.053      3.038      0.002       0.057       0.263\n",
       "Earthy           0.1425      0.041      3.495      0.000       0.063       0.223\n",
       "Flowery          0.2043      0.051      4.012      0.000       0.104       0.304\n",
       "Fruit            0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Grape            0.1928      0.067      2.876      0.004       0.061       0.324\n",
       "Grapefruit       0.1318      0.108      1.217      0.224      -0.081       0.344\n",
       "Honey            0.2269      0.118      1.924      0.055      -0.004       0.458\n",
       "Lavender         0.1748      0.110      1.587      0.113      -0.041       0.391\n",
       "Lemon            0.1698      0.057      2.966      0.003       0.058       0.282\n",
       "Lime             0.2569      0.094      2.746      0.006       0.073       0.440\n",
       "Mango            0.1520      0.116      1.314      0.189      -0.075       0.379\n",
       "Menthol          0.3414      0.138      2.474      0.013       0.071       0.612\n",
       "Mint             0.1778      0.154      1.154      0.249      -0.124       0.480\n",
       "Minty            0.3269      0.105      3.110      0.002       0.121       0.533\n",
       "Nutty            0.1307      0.130      1.005      0.315      -0.124       0.386\n",
       "Orange           0.1756      0.082      2.153      0.031       0.016       0.336\n",
       "Peach            0.4750      0.259      1.835      0.067      -0.033       0.983\n",
       "Pear             0.2176      0.367      0.594      0.553      -0.501       0.936\n",
       "Pepper           0.1970      0.089      2.216      0.027       0.023       0.371\n",
       "Pine             0.1902      0.050      3.774      0.000       0.091       0.289\n",
       "Pineapple        0.1847      0.106      1.745      0.081      -0.023       0.392\n",
       "Plum             0.0256      0.447      0.057      0.954      -0.851       0.903\n",
       "Pungent          0.1642      0.046      3.607      0.000       0.075       0.253\n",
       "Rose             0.1002      0.162      0.619      0.536      -0.217       0.418\n",
       "Sage             0.1884      0.107      1.768      0.077      -0.021       0.397\n",
       "Skunk            0.1866      0.059      3.152      0.002       0.071       0.303\n",
       "Spicy/Herbal     0.2020      0.053      3.788      0.000       0.097       0.307\n",
       "Strawberry       0.1300      0.098      1.326      0.185      -0.062       0.322\n",
       "Sweet            0.1798      0.040      4.484      0.000       0.101       0.258\n",
       "Tar              0.2833      0.239      1.183      0.237      -0.186       0.753\n",
       "Tea              0.0563      0.155      0.362      0.717      -0.249       0.361\n",
       "Tobacco         -0.0468      0.225     -0.208      0.835      -0.487       0.394\n",
       "Tree             0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Tropical         0.1833      0.063      2.922      0.004       0.060       0.306\n",
       "Vanilla          0.1465      0.117      1.249      0.212      -0.084       0.377\n",
       "Violet           0.1790      0.242      0.741      0.459      -0.295       0.653\n",
       "Woody            0.0860      0.053      1.631      0.103      -0.017       0.189\n",
       "==============================================================================\n",
       "Omnibus:                      557.494   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18579.690\n",
       "Skew:                          -0.454   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.965   Cond. No.                     1.48e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.95e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna \"tipo\" foi retirada, pois observamos que para os 3 diferentes tipos hibrida, sativa, indica o coeficiente era o mesmo, por isso usamos como se o \"tipo\" fosse sempre 1 no np.dot ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = datanova1[[  \n",
    "        'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted',  'Peach']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5615.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:39:31</td>     <th>  Log-Likelihood:    </th> <td> -2455.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4940.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2262</td>      <th>  BIC:               </th> <td>   5026.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.9061</td> <td>    0.053</td> <td>   17.089</td> <td> 0.000</td> <td>    0.802</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.9018</td> <td>    0.032</td> <td>   28.300</td> <td> 0.000</td> <td>    0.839</td> <td>    0.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.0000</td> <td>    0.357</td> <td>    5.605</td> <td> 0.000</td> <td>    1.300</td> <td>    2.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.9021</td> <td>    0.036</td> <td>   25.086</td> <td> 0.000</td> <td>    0.832</td> <td>    0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.8774</td> <td>    0.032</td> <td>   27.562</td> <td> 0.000</td> <td>    0.815</td> <td>    0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.8611</td> <td>    0.034</td> <td>   25.493</td> <td> 0.000</td> <td>    0.795</td> <td>    0.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.7955</td> <td>    0.046</td> <td>   17.351</td> <td> 0.000</td> <td>    0.706</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.8454</td> <td>    0.037</td> <td>   22.602</td> <td> 0.000</td> <td>    0.772</td> <td>    0.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.7991</td> <td>    0.038</td> <td>   20.758</td> <td> 0.000</td> <td>    0.724</td> <td>    0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>     <td>    2.0000</td> <td>    0.357</td> <td>    5.605</td> <td> 0.000</td> <td>    1.300</td> <td>    2.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    1.0731</td> <td>    0.036</td> <td>   29.830</td> <td> 0.000</td> <td>    1.003</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.8344</td> <td>    0.035</td> <td>   23.550</td> <td> 0.000</td> <td>    0.765</td> <td>    0.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.9007</td> <td>    0.041</td> <td>   21.754</td> <td> 0.000</td> <td>    0.819</td> <td>    0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.8262</td> <td>    0.042</td> <td>   19.731</td> <td> 0.000</td> <td>    0.744</td> <td>    0.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.8500</td> <td>    0.032</td> <td>   26.952</td> <td> 0.000</td> <td>    0.788</td> <td>    0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>     <td>    0.6033</td> <td>    0.293</td> <td>    2.062</td> <td> 0.039</td> <td>    0.030</td> <td>    1.177</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1419.293</td> <th>  Durbin-Watson:     </th> <td>   1.964</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>51287.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.373</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>25.761</td>  <th>  Cond. No.          </th> <td>2.45e+17</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.974\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     5615.\n",
       "Date:                Mon, 19 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        18:39:31   Log-Likelihood:                -2455.1\n",
       "No. Observations:                2277   AIC:                             4940.\n",
       "Df Residuals:                    2262   BIC:                             5026.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Aroused        0.9061      0.053     17.089      0.000       0.802       1.010\n",
       "Creative       0.9018      0.032     28.300      0.000       0.839       0.964\n",
       "Dry            2.0000      0.357      5.605      0.000       1.300       2.700\n",
       "Energetic      0.9021      0.036     25.086      0.000       0.832       0.973\n",
       "Euphoric       0.8774      0.032     27.562      0.000       0.815       0.940\n",
       "Focused        0.8611      0.034     25.493      0.000       0.795       0.927\n",
       "Giggly         0.7955      0.046     17.351      0.000       0.706       0.885\n",
       "Happy          0.8454      0.037     22.602      0.000       0.772       0.919\n",
       "Hungry         0.7991      0.038     20.758      0.000       0.724       0.875\n",
       "Mouth          2.0000      0.357      5.605      0.000       1.300       2.700\n",
       "Relaxed        1.0731      0.036     29.830      0.000       1.003       1.144\n",
       "Sleepy         0.8344      0.035     23.550      0.000       0.765       0.904\n",
       "Talkative      0.9007      0.041     21.754      0.000       0.819       0.982\n",
       "Tingly         0.8262      0.042     19.731      0.000       0.744       0.908\n",
       "Uplifted       0.8500      0.032     26.952      0.000       0.788       0.912\n",
       "Peach          0.6033      0.293      2.062      0.039       0.030       1.177\n",
       "==============================================================================\n",
       "Omnibus:                     1419.293   Durbin-Watson:                   1.964\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            51287.042\n",
       "Skew:                           2.373   Prob(JB):                         0.00\n",
       "Kurtosis:                      25.761   Cond. No.                     2.45e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.04e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto\n",
    "results = regress(xx,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos a retirada dos valores de \"p\" alto, ficamos com 15 variaveis, as quais estao citadas a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aroused      0.906083\n",
       "Creative     0.901776\n",
       "Dry          2.000000\n",
       "Energetic    0.902062\n",
       "Euphoric     0.877395\n",
       "Focused      0.861131\n",
       "Giggly       0.795519\n",
       "Happy        0.845407\n",
       "Hungry       0.799066\n",
       "Mouth        2.000000\n",
       "Relaxed      1.073139\n",
       "Sleepy       0.834394\n",
       "Talkative    0.900653\n",
       "Tingly       0.826177\n",
       "Uplifted     0.849996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variaveis = results.params[[ 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]\n",
    "Variaveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui foi usando o np.dot para conseguirmos prever nota esperada, dependendo das variaveis escolhidas. (Essa parte do teste ainda não esta completa, pretendemos formatar a apresentação com espaços para Input de cada característica na fabricação da maconha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4803301868117575"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Variaveis, np.array([0,0,0,0,1,0,0,1,0,0,1,1,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [ 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']\n",
    "lista_final = []\n",
    "i=1\n",
    "while i <= 15:\n",
    "    for e in lista:\n",
    "        ef = int(input(\"{} - \".format(e)))\n",
    "        if ef > 1:\n",
    "            print(\"Digite 1 para efeito desejado ou 0 para indesejado \")\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        if sum(lista_final)== 4 and ef == 1:\n",
    "            print('Você ja escolheu os 4 efeitos')\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        lista_final.append(ef)\n",
    "        i+=1\n",
    "    \n",
    "nota_final = np.dot(Variaveis, lista_final)\n",
    "print('Os efeitos que você escolheu deixam a sua strain com uma nota aproximadamente igual a {}'.format(nota_final))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista que a classificação dos diferentes strains leva em conta as sensações e(...) do usuário, a análise deveria se embasar naquilo que apesar de subjetivo, pudesse ser perceptível por diversos usuários. Dessa forma, avaliar sabores, como constatamos pela análise não seria um bom viés, por ser extremamente subjetivo, cada usuário teria uma preferência diferente. A eficiência então da starn poderia ser avaliada.\n",
    "\n",
    "Na criação de novas strains, por meio da manipulação de duas ou mais já existentes, leva-se em consideração os índices de TCH e CDI de cada substância. A proporção de tais valores é fator limitante para a criação de novas strains com efeitos desejados. Portanto, saber quais efeitos se deseja obter, tendo em vista seu impacto individual na avaliação final dos usuários contribui para determinar a proporção de TCH e CDI. É importante ressaltar que o grau do efeito, não apenas se ele existe ou não contribui para a nota (fonte), fator que poder ter diminuído a acurácia de nosso teste por não termos dados. Por outro lado, pode-se afirmar que, no desenvolvimento de uma nova strain, focar na causa mais intensa daqueles efeitos que possuem maior coeficiente em nossa regressão (como Dry, Mouth, Aroused, Energetic) pode culminar para uma melhor avaliação dos usuários também, pois são efeitos mais valorizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probplot(datanova1, dist = 'norm', plot = plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
