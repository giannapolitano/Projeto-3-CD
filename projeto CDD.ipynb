{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># **Ciência dos Dados** <font color=purple>- Projeto 3</font>\n",
    "   #### <font color=grey> <p>Gianlucca de La Torre Napolitano </p> <p>Lucas Nicascio dos Santos</p> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação do peso de características a serem destacadas na fabricação da maconha e seus impactos na avaliação final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O projeto visa a análise de características presentes na Maconha como seus efeitos, sabor e tipo, de forma a prever quais os fatores devem ser mais focados na fabricação de forma a obter uma ótima avaliação pelo público, tendo em vista que as características podem ser ajustadas pelas proporções de THC (Tetrahidrocanabinol) e CBD (Canabidiol) (não aprofundados nesse projeto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente é necessário ler o Dataset \"Cannabis Strains\" obtido na plataforma Kaggle, bem como criar um Data Frame ábil para análise, pois contém variáveis qualitativas e quantitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gian.napolitano/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from scipy.stats import beta, probplot\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos arquivos em .csv e eliminação dos valores nulos do DataFrame \n",
    "df = pd.read_csv('cannabis.csv')\n",
    "data = df.dropna(how = 'any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classificação dos valores em \"Type\" em colunas de 0 e 1 para equivalência de variáveis qualitativas em quantitativas\n",
    "\n",
    "tipo = np.array(data.Type)\n",
    "label_encoder = LabelEncoder()\n",
    "Type_quan = label_encoder.fit_transform(tipo)\n",
    "Type_quan\n",
    "data = data.assign(Tipo = Type_quan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Effects\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "efeitos = data['Effects'].str.get_dummies(sep=',')\n",
    "efeitos = efeitos.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "data_nova = data.join(efeitos, how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Flavours\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "sabores = data['Flavor'].str.get_dummies(sep=',')\n",
    "sabores = sabores.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "datanova = data_nova.join(sabores, how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de colunas não mais necessárias do DataFrame\n",
    "datanova1 = datanova.drop(['Effects','Flavor','Type','Strain','Description'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress1(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método escolhido para desenvolver o projeto foi a Regressão Linear Múltipla, ou seja, estimar uma condicional de uma variável y, dado os valores de outras variáveis. <p>Determinação das variáveis a serem utilizadas na regressão: A variável x foi separada de duas formas para testarmos a hipótese de que os sabores podem não ter um efeito significativo na regressão, pois são avaliados de forma subjetiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['Tipo', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.427</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>1.02e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:29:56</td>     <th>  Log-Likelihood:    </th> <td> -2115.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4359.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2213</td>      <th>  BIC:               </th> <td>   4726.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    63</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    1.6989</td> <td>    0.066</td> <td>   25.856</td> <td> 0.000</td> <td>    1.570</td> <td>    1.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>         <td>    0.0022</td> <td>    0.018</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.033</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.4591</td> <td>    0.051</td> <td>    8.934</td> <td> 0.000</td> <td>    0.358</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.4616</td> <td>    0.035</td> <td>   13.014</td> <td> 0.000</td> <td>    0.392</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.0578</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.4491</td> <td>    0.039</td> <td>   11.553</td> <td> 0.000</td> <td>    0.373</td> <td>    0.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.4446</td> <td>    0.036</td> <td>   12.431</td> <td> 0.000</td> <td>    0.374</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.4285</td> <td>    0.037</td> <td>   11.642</td> <td> 0.000</td> <td>    0.356</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.3655</td> <td>    0.045</td> <td>    8.072</td> <td> 0.000</td> <td>    0.277</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.4258</td> <td>    0.040</td> <td>   10.639</td> <td> 0.000</td> <td>    0.347</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.3728</td> <td>    0.040</td> <td>    9.320</td> <td> 0.000</td> <td>    0.294</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.0578</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.5692</td> <td>    0.041</td> <td>   13.942</td> <td> 0.000</td> <td>    0.489</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.4123</td> <td>    0.038</td> <td>   10.782</td> <td> 0.000</td> <td>    0.337</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.4530</td> <td>    0.043</td> <td>   10.658</td> <td> 0.000</td> <td>    0.370</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.3969</td> <td>    0.042</td> <td>    9.370</td> <td> 0.000</td> <td>    0.314</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.4256</td> <td>    0.035</td> <td>   12.069</td> <td> 0.000</td> <td>    0.356</td> <td>    0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2174</td> <td>    0.125</td> <td>    1.740</td> <td> 0.082</td> <td>   -0.028</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>   -0.0948</td> <td>    0.164</td> <td>   -0.579</td> <td> 0.563</td> <td>   -0.416</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.1051</td> <td>    0.225</td> <td>    0.467</td> <td> 0.640</td> <td>   -0.336</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2103</td> <td>    0.049</td> <td>    4.287</td> <td> 0.000</td> <td>    0.114</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1263</td> <td>    0.227</td> <td>   -0.557</td> <td> 0.577</td> <td>   -0.571</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.1744</td> <td>    0.065</td> <td>    2.668</td> <td> 0.008</td> <td>    0.046</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.0985</td> <td>    0.148</td> <td>    0.664</td> <td> 0.507</td> <td>   -0.193</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0446</td> <td>    0.092</td> <td>    0.484</td> <td> 0.629</td> <td>   -0.136</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.1902</td> <td>    0.110</td> <td>    1.728</td> <td> 0.084</td> <td>   -0.026</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.0429</td> <td>    0.261</td> <td>    0.164</td> <td> 0.869</td> <td>   -0.469</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.1615</td> <td>    0.045</td> <td>    3.556</td> <td> 0.000</td> <td>    0.072</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.2961</td> <td>    0.134</td> <td>    2.210</td> <td> 0.027</td> <td>    0.033</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.1598</td> <td>    0.053</td> <td>    3.038</td> <td> 0.002</td> <td>    0.057</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1425</td> <td>    0.041</td> <td>    3.495</td> <td> 0.000</td> <td>    0.063</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2044</td> <td>    0.051</td> <td>    4.018</td> <td> 0.000</td> <td>    0.105</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.1933</td> <td>    0.067</td> <td>    2.892</td> <td> 0.004</td> <td>    0.062</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1318</td> <td>    0.108</td> <td>    1.218</td> <td> 0.223</td> <td>   -0.080</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2271</td> <td>    0.118</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.004</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.1748</td> <td>    0.110</td> <td>    1.587</td> <td> 0.113</td> <td>   -0.041</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.1697</td> <td>    0.057</td> <td>    2.965</td> <td> 0.003</td> <td>    0.057</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2570</td> <td>    0.094</td> <td>    2.748</td> <td> 0.006</td> <td>    0.074</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1518</td> <td>    0.116</td> <td>    1.313</td> <td> 0.189</td> <td>   -0.075</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.3415</td> <td>    0.138</td> <td>    2.476</td> <td> 0.013</td> <td>    0.071</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.1779</td> <td>    0.154</td> <td>    1.155</td> <td> 0.248</td> <td>   -0.124</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3271</td> <td>    0.105</td> <td>    3.114</td> <td> 0.002</td> <td>    0.121</td> <td>    0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.1310</td> <td>    0.130</td> <td>    1.007</td> <td> 0.314</td> <td>   -0.124</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.1755</td> <td>    0.082</td> <td>    2.153</td> <td> 0.031</td> <td>    0.016</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.4743</td> <td>    0.259</td> <td>    1.834</td> <td> 0.067</td> <td>   -0.033</td> <td>    0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2177</td> <td>    0.366</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.501</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.1972</td> <td>    0.089</td> <td>    2.220</td> <td> 0.027</td> <td>    0.023</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.1902</td> <td>    0.050</td> <td>    3.775</td> <td> 0.000</td> <td>    0.091</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.1843</td> <td>    0.106</td> <td>    1.744</td> <td> 0.081</td> <td>   -0.023</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0255</td> <td>    0.447</td> <td>    0.057</td> <td> 0.954</td> <td>   -0.851</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.1644</td> <td>    0.045</td> <td>    3.617</td> <td> 0.000</td> <td>    0.075</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1004</td> <td>    0.162</td> <td>    0.621</td> <td> 0.535</td> <td>   -0.217</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.1884</td> <td>    0.107</td> <td>    1.769</td> <td> 0.077</td> <td>   -0.020</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.1866</td> <td>    0.059</td> <td>    3.152</td> <td> 0.002</td> <td>    0.070</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2020</td> <td>    0.053</td> <td>    3.788</td> <td> 0.000</td> <td>    0.097</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1297</td> <td>    0.098</td> <td>    1.325</td> <td> 0.185</td> <td>   -0.062</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.1798</td> <td>    0.040</td> <td>    4.485</td> <td> 0.000</td> <td>    0.101</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.2829</td> <td>    0.239</td> <td>    1.182</td> <td> 0.237</td> <td>   -0.186</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0562</td> <td>    0.155</td> <td>    0.361</td> <td> 0.718</td> <td>   -0.249</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0468</td> <td>    0.225</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.487</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.1831</td> <td>    0.063</td> <td>    2.922</td> <td> 0.004</td> <td>    0.060</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1464</td> <td>    0.117</td> <td>    1.248</td> <td> 0.212</td> <td>   -0.084</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.1789</td> <td>    0.242</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.295</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.0861</td> <td>    0.053</td> <td>    1.636</td> <td> 0.102</td> <td>   -0.017</td> <td>    0.189</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>557.472</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18573.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.454</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.962</td>  <th>  Cond. No.          </th> <td>1.15e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.443\n",
       "Model:                            OLS   Adj. R-squared:                  0.427\n",
       "Method:                 Least Squares   F-statistic:                     27.92\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):          1.02e-232\n",
       "Time:                        10:29:56   Log-Likelihood:                -2115.6\n",
       "No. Observations:                2277   AIC:                             4359.\n",
       "Df Residuals:                    2213   BIC:                             4726.\n",
       "Df Model:                          63                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            1.6989      0.066     25.856      0.000       1.570       1.828\n",
       "Tipo             0.0022      0.018      0.125      0.901      -0.033       0.037\n",
       "Aroused          0.4591      0.051      8.934      0.000       0.358       0.560\n",
       "Creative         0.4616      0.035     13.014      0.000       0.392       0.531\n",
       "Dry              1.0578      0.340      3.116      0.002       0.392       1.724\n",
       "Energetic        0.4491      0.039     11.553      0.000       0.373       0.525\n",
       "Euphoric         0.4446      0.036     12.431      0.000       0.374       0.515\n",
       "Focused          0.4285      0.037     11.642      0.000       0.356       0.501\n",
       "Giggly           0.3655      0.045      8.072      0.000       0.277       0.454\n",
       "Happy            0.4258      0.040     10.639      0.000       0.347       0.504\n",
       "Hungry           0.3728      0.040      9.320      0.000       0.294       0.451\n",
       "Mouth            1.0578      0.340      3.116      0.002       0.392       1.724\n",
       "Relaxed          0.5692      0.041     13.942      0.000       0.489       0.649\n",
       "Sleepy           0.4123      0.038     10.782      0.000       0.337       0.487\n",
       "Talkative        0.4530      0.043     10.658      0.000       0.370       0.536\n",
       "Tingly           0.3969      0.042      9.370      0.000       0.314       0.480\n",
       "Uplifted         0.4256      0.035     12.069      0.000       0.356       0.495\n",
       "Ammonia          0.2174      0.125      1.740      0.082      -0.028       0.463\n",
       "Apple           -0.0948      0.164     -0.579      0.563      -0.416       0.226\n",
       "Apricot          0.1051      0.225      0.467      0.640      -0.336       0.546\n",
       "Berry            0.2103      0.049      4.287      0.000       0.114       0.307\n",
       "Blue            -0.1263      0.227     -0.557      0.577      -0.571       0.318\n",
       "Blueberry        0.1744      0.065      2.668      0.008       0.046       0.303\n",
       "Butter           0.0985      0.148      0.664      0.507      -0.193       0.390\n",
       "Cheese           0.0446      0.092      0.484      0.629      -0.136       0.225\n",
       "Chemical         0.1902      0.110      1.728      0.084      -0.026       0.406\n",
       "Chestnut         0.0429      0.261      0.164      0.869      -0.469       0.554\n",
       "Citrus           0.1615      0.045      3.556      0.000       0.072       0.251\n",
       "Coffee           0.2961      0.134      2.210      0.027       0.033       0.559\n",
       "Diesel           0.1598      0.053      3.038      0.002       0.057       0.263\n",
       "Earthy           0.1425      0.041      3.495      0.000       0.063       0.222\n",
       "Flowery          0.2044      0.051      4.018      0.000       0.105       0.304\n",
       "Fruit            0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Grape            0.1933      0.067      2.892      0.004       0.062       0.324\n",
       "Grapefruit       0.1318      0.108      1.218      0.223      -0.080       0.344\n",
       "Honey            0.2271      0.118      1.926      0.054      -0.004       0.458\n",
       "Lavender         0.1748      0.110      1.587      0.113      -0.041       0.391\n",
       "Lemon            0.1697      0.057      2.965      0.003       0.057       0.282\n",
       "Lime             0.2570      0.094      2.748      0.006       0.074       0.440\n",
       "Mango            0.1518      0.116      1.313      0.189      -0.075       0.379\n",
       "Menthol          0.3415      0.138      2.476      0.013       0.071       0.612\n",
       "Mint             0.1779      0.154      1.155      0.248      -0.124       0.480\n",
       "Minty            0.3271      0.105      3.114      0.002       0.121       0.533\n",
       "Nutty            0.1310      0.130      1.007      0.314      -0.124       0.386\n",
       "Orange           0.1755      0.082      2.153      0.031       0.016       0.335\n",
       "Peach            0.4743      0.259      1.834      0.067      -0.033       0.981\n",
       "Pear             0.2177      0.366      0.594      0.553      -0.501       0.936\n",
       "Pepper           0.1972      0.089      2.220      0.027       0.023       0.371\n",
       "Pine             0.1902      0.050      3.775      0.000       0.091       0.289\n",
       "Pineapple        0.1843      0.106      1.744      0.081      -0.023       0.392\n",
       "Plum             0.0255      0.447      0.057      0.954      -0.851       0.902\n",
       "Pungent          0.1644      0.045      3.617      0.000       0.075       0.254\n",
       "Rose             0.1004      0.162      0.621      0.535      -0.217       0.418\n",
       "Sage             0.1884      0.107      1.769      0.077      -0.020       0.397\n",
       "Skunk            0.1866      0.059      3.152      0.002       0.070       0.303\n",
       "Spicy/Herbal     0.2020      0.053      3.788      0.000       0.097       0.307\n",
       "Strawberry       0.1297      0.098      1.325      0.185      -0.062       0.322\n",
       "Sweet            0.1798      0.040      4.485      0.000       0.101       0.258\n",
       "Tar              0.2829      0.239      1.182      0.237      -0.186       0.752\n",
       "Tea              0.0562      0.155      0.361      0.718      -0.249       0.361\n",
       "Tobacco         -0.0468      0.225     -0.208      0.835      -0.487       0.394\n",
       "Tree             0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Tropical         0.1831      0.063      2.922      0.004       0.060       0.306\n",
       "Vanilla          0.1464      0.117      1.248      0.212      -0.084       0.376\n",
       "Violet           0.1789      0.242      0.741      0.459      -0.295       0.653\n",
       "Woody            0.0861      0.053      1.636      0.102      -0.017       0.189\n",
       "==============================================================================\n",
       "Omnibus:                      557.472   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18573.235\n",
       "Skew:                          -0.454   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.962   Cond. No.                     1.15e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.29e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress1(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XuclHXd//HXh5UzCgp4AGVXzVQ8Jqt4SCNBQQUGO3djeai4gSzurCzDXx666ba8tazuMjLTcuv2tsMOIMhBxVNqAuFZy9OKSIoiclZgP78/vteyw7Jz2N2ZuWZm38/HYx87c83sdX12xesz39Pna+6OiIhIl7gDEBGR0qCEICIigBKCiIhElBBERARQQhARkYgSgoiIAEoI0gmY2ZVmdls7f/YCM3sww+vzzOz81t5rZhvM7KD2XLeNMS42sy8W+jpS+ZQQpCSZ2Stmtjm6qb5hZr8xsz5xx9WSu5/l7remea2Pu78EYGa3mNl/tvc6+fh7mFmNmbmZ7dbeOKSyKSFIKRvn7n2A44DjgctbvsGCzvLvOOvfQ6QjOsv/SFLG3H0lMA84EnZ0kcwws4eATcBBZjbIzGaZ2Roze8HMvtTiND3M7HYzW29my8zsmKYXzOzbZvZi9NozZnZui581M/upmb1rZs+Z2ciUF9J210Sfxj9gZpOAicCl0Sf82Wb2TTP7U4v3/9TMftzWv0eLc3Qxs8vNrMHM3jSz35pZ3+jl+6Pva6M4Tsp2LelclBCk5JnZAcDZwN9TDn8OmATsDjQAfwBeAwYBnwC+n3rjBhLAHcBewO+BejPrGr32InAq0Be4CrjNzPZL+dnhwEvAAOAK4M9mtleu8bv7TKAO+GHUjTQOuA0YY2b9ot9xN+DTwO+ynS/N36PJBdHXR4GDgD7Az6LXTou+94vieDjX30E6ByUEKWX1ZrYWeBC4D/h+ymu3uPvT7r4N2Bf4MPAtd9/i7suBmwhJo8lSd/+ju28Frgd6ACcCuPsd7v66uze6++3AP4ETUn72TeDH7r41ev154JyO/GLuvorwif2T0aExwFvuvjTDj2X6ezSZCFzv7i+5+wbgMuAzGjeQXOgfiZSyCe6+KM1rK1IeDwLWuPv6lGMNQG1r73f3RjNrak1gZp8HLgFqorf0IbQGmqz0natANjT9bAfdCkwBfgWcR/bWQaa/R5NBhPiaNBD+P9+nvUFK56EWgpSr1Bv068BeZrZ7yrEhwMqU5wc0PYgGofcHXjezasIN+WKgv7v3A54CLOVnB5tZ6vMh0TXbG2+TeuBoMzsSGEvoVuqo14HqlOdDgG3AG2liENlBCUHKnruvAP4K/JeZ9TCzo4EvsPMNdpiZfSzqOvkP4D3gEaA34Ua5GsDMLmTXwdq9ga+aWVcz+yRwODC3jWG+QejTT417C/BHwpjG39z91TaeszV/AL5mZgdG01K/D9weda2tBhpbxiHSRAlBKsVnCV0+rwN/Aa5w94UprycJg7bvEMYWPhaNCTwDXAc8TLhpHwU81OLcjwKHAG8BM4BPuPvbbYzv18BQM1trZvUpx2+Nrpl1MDlHN0fnuh94GdgCfAXA3TcR4n8oiuPEPF1TKoRpgxyR+JjZEOA5YF93Xxd3PNK5qYUgEpNoLOMS4H+VDKQUaJaRSAzMrDehi6qBMOVUJHbqMhIREUBdRiIiEimrLqMBAwZ4TU1N3GGIiJSVpUuXvuXuA7O9r6wSQk1NDUuWLIk7DBGRsmJmDdnfpS4jERGJKCGIiAighCAiIhElBBERAZQQREQkooQgItKKujqoqQEz2G231r8PGBC+unTZ+XFNDUydGr43Pa+r2/m8LY9niyPX93dEWa1Urq2tdU07FZFCq6uDSZNg06b8nbNXLzj/fLj11p3P26sXzJwJEyfmFkem96djZkvdvTbr+5QQRER2VlMDDTnN3G+bqirYvn3X49XV8MoruceR7v3p5JoQ1GUkItLCq/nYqqgVrSWDTNdr6/GOUkIQEWlhyJDCnLeqqm3Xa+vxjlJCEBFpYcaM0FefT716hfGAluft1StcL9c4Mr2/o5QQRERamDgxDNxWV4fnTZ/sW37v3z98me38uLoapkwJ35uez5wJP/9583lTj6cbIE6NI5f3d5QGlUVEKlzJDyqbWQ8z+5uZPW5mT5vZVXHFIiICYZrngAHh03jTOoNCzvsvNXGWv34PON3dN5hZV+BBM5vn7o/EGJOIdFJ1dXDhhbB1a/Oxt9+Giy4KjwvVTVNKYmsheLAheto1+iqf/isRqSjTp++cDJq8/354rTOIdVDZzKrMbDnwJrDQ3R9t5T2TzGyJmS1ZvXp18YMUkYpXV5d5IVqh5v2XmlgTgrtvd/djgf2BE8zsyFbeM9Pda929duDArDvAiYjkrK4O+vSB887L/L5CzfsvNSUx7dTd1wKLgTExhyIinUTTmMHGjZnf161b4eb9l5o4ZxkNNLN+0eOewCjgubjiEZHOJd2YQar+/eHmmzvHgDLEO8toP+BWM6siJKb/c/c5McYjIp1ItuJ1bS0gVwliSwju/gTwobiuLyKdV11dWGeQbl2uWefpJkpVEmMIIiLFNG1a+mQAMHly5+kmShVnl5GISNHV1YUFZ+ncdlvnTAagFoKIdDKZFplVV3feZABKCCLSyWRaZNYZxw1SKSGISKeSbpFZ//6du3UASggi0smk23TmhhviiaeUKCGISKdS7E1nyolmGYlIp1FXF6acNs0y6t8/tBiUDAIlBBHpFLTfQXbqMhKRijN1KnTp0rzzmVmoaNrZ9zvIRi0EEakoU6fCL37Rtp/pLPsdZKMWgohUlJkz2/4znWW/g2yUEESkomzf3rb3d6b9DrJRQhCRilFX17b3d+nSufY7yEYJQUQqxrRpub+3Wzf47W+VDFIpIYhIRchWxTRVZ9sJLVexzTIyswOA3wL7Ao3ATHfX4nERaZdsVUw72+5n7RHntNNtwNfdfZmZ7Q4sNbOF7v5MjDGJSJnKtCWmBo1zE1uXkbuvcvdl0eP1wLPA4LjiEZHylWkw2UxdQ7kqiTEEM6sh7K/8aCuvTTKzJWa2ZPXq1cUOTUTKQKbB5ExbZcrOYk8IZtYH+BPwH+6+ruXr7j7T3WvdvXbgwIHFD1BEStqoUZkHk6urixdLuYs1IZhZV0IyqHP3P8cZi4iUn1Gj4O67M79H4we5iy0hmJkBvwaedffr44pDRMpTXV32ZAAVMH6weTPMng0bNhT8UnG2EE4BPgecbmbLo6+zY4xHRMpILhVKy7a76K234NZb4dxzYcAAGD8e5s8v+GVjm3bq7g8CFtf1RaS8ZZpmCmVYo+jFFyGZDF8PPgiNjTB4MFxwASQSMGJEwUNQ+WsRKTtTp2Z+vUcPuOmmEu8ucoelS6G+PiSBp54Kx486Cr7zHZgwAY47LsybLRIlBBEpK3V12fc72Ly5OLG02fvvw733hgQwaxasXBkq7J16Klx/fWgJHHRQbOEpIYhIWbnggsyvl9y4wbvvwty5IQnMmwfr1kGvXjB6dGgFnHNOKK5UApQQRKRsTJ0K27Zlfk9JjBusWBFaAMlkaBFs2wZ77w2f+lRoBYwcCT17xh3lLpQQRKRsZNsNrXfvmMYN3OHJJ5sHhZcuDcc/+EG45JKQBIYPh6qqGILLnRKCiJSNbLuh/fKXxYkDCJ/6H3ywOQm8/HIYAD7xRLjmmpAEDjusiAF1nBKCiJSFbLuhjRxZhNbBxo1hPUAyCXPmwJo10L17WDJ92WUwbhzsu2+BgygcJQQRKQuTJ6d/behQWLSoQBd+442wUjiZhIUL4b33YM89YezY0AoYPRr69CnQxYtLCUFESl5dXebKDU8/necLPv98SAD19fDII2GMoKYmZKVEIkwT3a3ybp+V9xuJSMXJNtW0wxob4dFHm5PA88+H48cdB1deGaaHHnVUUReJxUEJQURKWrappu2ewr9lS6iOV18fuoTeeCN86h8xAi6+ONQPGjKknScvT0oIIlLSss0cuqEtO7GvWQN33hmSwPz5YZB4993hrLNCK+Css6Bfvw7FW86UEESkpDU2Zn4968yil19unhr6wANh7uqgQfD5zzcXjevePV/hljUlBBEpW1OmtHLQHZYta04CTzwRjh9xBHz72yEJDBsWagjJTpQQRKRkZapqWlUFP/959OT99+G++5qLxq1YEW74H/4wXHddSAIHH1yUmMuZEoKIlJxctsas+8U6uH1eSAJz54Yicj17hnUBV18d1gkMGFCcgCuEEoKIlJQjjoBnnmn9tUGsZDyzSJBkzJfvga1bYeBA+PjHQytg1KhQSVTaJdaEYGY3A2OBN939yDhjEZH41dW1TAbOETxNgiQJkpzAYwD8g0Ng2rSQBE46qeSLxpWLuFsItwA/A34bcxwiErOmbqIqtnEyfyVBkgnUczAvAfAIw7mM71PPBFbvdRhvXVvZi8TiEGtCcPf7zawmzhhEJH7DDt/EAc8t4DfUM5Y5DOBt3qMbdzOSH3IpsxnHKgbteP9tP4kx2AoWdwshKzObBEwCGNLJVg2KVLQ334Q5c3ji6noebFhIT7bwDv24k3OoZwLzGc0Gdt/lx4pS1bSTKvmE4O4zgZkAtbW1HnM4ItIR//znjk3l/a9/xdzpyxBmMokkCR7gVLbRNe2PT5mSMtVU8q7kE4KIlLHGRnjssR1JgGefBWBN9bHc4FeQJMHjHANkHg/o3TtztVPJjzYlBDPbEzjA3Z8oUDwiUu62bIF77gkJYPZsWLUqzAIaMSJ8xB8/nsGHVbOlDacs6k5onVjWhGBmi4Hx0XuXA6vN7D53v6SjFzezPwAjgAFm9hpwhbv/uqPnFZEie+edUDQumYS77gof5/v0CcXiEgk4++ywqQxhncGWHLPBbrvBLbdozKBYcmkh9HX3dWb2ReA37n6FmeWlheDun83HeUQkBg0NzfWC7rsvFI3bb79w904k4PTTdykaN2pU+kVnLQ0dWoCNbySjXBLCbma2H/ApYHqB4xGRUuUOy5c3J4Hly8PxoUPh0ktDEjj++LRF43r1gs2bc7tUv35KBnHIJSFcDcwHHnL3x8zsIOCfhQ1LRErC1q1w//3NSeDVV8OuYaecAtdeG5LAIYfs8mODB8Prr7fvkiNHFnB/ZMkoa0Jw9zuAO1KevwR8vJBBiUiM1q8P4wDJZBgXWLsWevSAM8+EK64IReP23nunH6mrg/PO6/illQzilcug8geBXwD7uPuRZnY0MN7d/7Pg0YlIcaxaFcpG19eHGULvvx8qhU6YEL7OOGOnonH5SgCphg5VMohbLl1GvwK+CfwSwN2fMLPfA0oIIuXKPawJaNpU/m9/C8cPPjjsJzxhApx8MlRVhZt/78KGM2iQxgxKQS4JoZe7/81sp4UjGba8FpGStH07PPxw8yKxF14Ix48/HmbMCOMBQ4dS93vjvNOKF1bPnrByZfGuJ+nlkhDeMrODAQcws08AqwoalYjkx6ZNoR+mvh7mzIHVq6Fr19BZ//Wvw7hxMHgwZsQyh1BjBqUll4TwZUItocPMbCXwMpDn3kMRyZvVq8PNP5mEBQvCXM++feGcc0IrYMwYrO8ecBfQ2p7ERTBokFoFpSiXWUYvAaPMrDfQxd3XFz4sEWmTF15onhr60EOhhtABB8AXvsCYXyS4593T2Pr7bvD74odmBr/7nVYbl4NcZhl9t8VzANz96gLFJCLZNDbCkiXNSaBpRPaYY7iq8XKSJPj7ig/Bz+LZRKZfv1DNQspLLl1GG1Me9yBseflsYcIRkbTeew/uvTckgFmzwsqvqiru2X4aSb5EkgQNj9fEElrPnmG4QspbLl1G16U+N7P/BmYVLCIRabZ2LcydG5LAvHmwfj0b6M1djCFJgju3n8M77FXUkLp2DcsUpPK0Zz+EXsBB+Q5ERCIrVkAyycKvJBnBYrqyjX+xD7P4DEkS3M1I3qNH0cLp0iXMWJXKl8sYwpNEU06BKmAgob6RiOSDO7XdnuDsbUkSJBnGMgD25zCu4+skSfAow3FaLxpXoJCkE8qlhTA25fE24A1318I0kXZoKvlQxTZO5QEShCSwhFdoxHiYk7iUH5AkwT84tGhxaWtKgQwJwcyaOiZbTjPdw8xw9zWFC0uk/LWs+NmbDYxmPreSZCxz2It32EJ3FnIG/8nlzGEsb7JPwePSGgBJJ1MLYSmhq6i1eWtOHsYRzGwMcAOhK+omd7+mo+cUicOoUXD33bse34d/MY7ZTKCekdxND97jbfZiNuOoZwILOJNNFLZQkFYDS67SJgR3P7CQFzazKuB/gDOA14DHzGyWu+e4n5JI8eVS5/9QnmMC9SRIMpxH6YLzEgfyc6aSJMFDnML2ds3nyI2mgEp75fSv0sz2BA6B5qkN7n5/B699AvBCtBIaM/tfIAEoIUjsrA3rubqwneE8uiMJHMo/AHiMWr7L1SRJ8BRH0npju+M0ACz5ksssoy8C04D9geXAicDDwOkdvPZgYEXK89eA4R08p0ibtOXGn6oHmxnFIhIkGcds9uFN3qcr9/JRbmAasxjPSvbPa6zq+5dCy6WFMA04HnjE3T9qZocBV+Xh2unGJnZ+k9kkYBLAkCFD8nBZ6Yzae+NPtRdvM5Y5JEgymvn0ZhPvsgdzOZskCeZxFuvo2/ELRfTJX4otl4Swxd23mBlm1t3dnzOzfMyHew04IOX5/sAuvbPuPpNQbZXa2lr9LyJZ5ePm3+RAXtoxNfRUHqCKRl5jMLdwAUkSLGYEW+nWoWvoxi+lIpeE8JqZ9QPqgYVm9g6t3Ljb4THgEDM7EFgJfAb4tzycVzqJfN74mznDWLojCRzNkwA8wVF8n++QJMFShtHe8QDd/KWU5VLL6Nzo4ZVmdi/Ql1BJvUPcfZuZXQzMJ0w7vdndtYme7KIwN/5mXXmfESwmQZLxzOIAXmM7XXiAU/ka15MkwcvtmGWtm7+Um0wL0+4kVE+vd/eNAO5+Xz4v7u5zgbn5PKeUr6qqUNW5GPbgXc5iHgmSnM1c+rKOjfRiPqOZzgzu5BzW0D+nc+nGL5UiUwthJqEb58dmdg/wB2Cuu6vOoXRIU/mGYhvMa4xnFhOoZwSL6cZW3mBv7uCT1DOBuxnJFnq2+rOa4SOdQaaFaUkgaWY9gfHA+cCNZjYX+IO7LyxSjFLmCt3lk55zJE+RIMkE6qllKQDP80F+xNd2FI1rpGrHT6i0s3RmuYwhbAZuB243s6OBWwnJoSrjD0qn1qtX2Mq32KrYxik8tGOR2EG8TCPGI5zIt7iGJAme5zB94hdpRS4L0/YBPkXoPtoPuAO4sMBxSRk64gh4JoZ15r3YyJksYAL1jGUO/VnDFrqziFH8F5fR//xxXHPLvpwM/KD44YmUjUyDyl8CPgscCvwZuNTdHypWYFI+cqnvk2978wbjmE2CJKNYRE+28I7tyZ7njYVEgh6jRzO2T5+dareLSGaZWggnA9cAi9y9SHM/pJykq/BZKIfwDyZQzw9PTsLDD4fpPTU1kPh3SCTY89RTYbfCFY0TqXSZBpXVLSStKlaL4IjDG3nq14+G/YSTSXjuufDCluPgyishkYCjj45z1FqkoujjlORszz3Dnu+FsGMu/5YtodmRTMLs2XDyv8Kn/hEj4MtfhvHjQTWtRApCCUGyyudgcasbtq9ZA7+7MySBu+6CjRth993hrLNgwoTwvV+//AQgImnlsoVmq7SFZuWbOhV+8Yv8nGuXPXtfeaW5K+j++0OWGDQIPve5kARGjIDu3fNzcRHJSa5baA4B3oke9wNeBQq6o5rEKx/dQ0OHwtNN1ancYdnfQwKor4cnngjHjzgCvv3tMB4wbFhoQohILLJuoWlmNwKzorpDmNlZwKjihCdxGDy4Y8lgR2tg61ZYdF9zS2DFinDDP+UUuO66kAQOPjhvcYtIx+QyhnC8u09ueuLu88zsewWMSWLUkRlEQ4fC0w+vC+MA/1YPc+fCu++GTX5Hj4arr4ZzzoGBA/MbtIjkRS4J4S0zuxy4jdCFdB7wdkGjkqJrb8E5M/jjT17nY7vNCl1BA+4JLYOBA+HjHw+tgFGjQi0LESlpuSSEzwJXAH8hJIT7o2NSIdqeDJxjdnuG5VfWh66grzwWDn/gAzBtWkgCJ50U6lmLSNkwz7GYu5n1cfcNBY4no9raWl+yZEmcIVSknj3D9P9MurCdU3iIBEk+t0eSvde9GF4YPjwkgEQCDj9ci8RESpCZLXX32mzvy6W43cnATUAfYIiZHQP8u7tP7XiYErdRo9Ing55s4kwWkCDJWOYwkLegWzc4ZSQkvgnjxoWpoiJSEXLpMvoRMBqYBeDuj5vZaR25qJl9ErgSOBw4wd31sT8GdXW71iIawOodRePOYCG92Mw79OPBvucw7qYJYXB4993jCVhECiqnlcruvsJ27gpouda0rZ4CPgb8soPnkQ6YHM0d+wD/3LGp/Ck8RBecBoZwE1+kngm8ffipPP5M13iDFZGCyyUhrIi6jdzMugFfBZ7tyEXd/VkAU39zPBob4bHHuGxDSAJHEOpS/J1juYorSJLgcY4BjNtug4kT4w1XRIojl4QwGbgBGAy8BiwAvlzIoFKZ2SRgEsAQFTVrv/feg3vuCbOCZs2CVau4lCru4yPcyGRmMZ5Xqd7pR6ZMUTIQ6UwyJgQzqwI+5+5tvi2Y2SJg31Zemh7t15wTd58JzIQwy6itcXRq77wTFoclkzBvHmzYAH36wFln8YVZCf783tmsZc9Wf3To0Ba1h0Sk4mVMCO6+3cwShIHlNnF3lbeIw6uvNpeKuO8+2LYN9tsvfNRPJOD006n7Y3duviPzaXbUIBKRTiOXLqOHzOxnwO3AxqaD7r6sYFFJ7tzh8cebi8YtXx6ODx0K3/xmSALHH79T0bhp0zKfsro68+siUplySQgnR9+vTjnmwOntvaiZnQv8FBgI3Glmy919dHvP1+ls3QoPPBASwKxZ0NAQFoSdcgpce21IAocckvbH385SeGTGjDzHKyJlIeeVyqWgU69UXr8e5s8PSeDOO0M50h494MwzQwIYOxb23junU2Wb3FVG/yREJAf5XKm8D/B9YJC7n2VmQ4GT3P3XeYhTMlm1KrQAksmwguz996F//7CBzIQJcMYZeS8aN2VKXk8nImUkly6jW4DfANOj5/8gjCcoIeSbe9hIvj4qGvfoo+H4wQfDxReHJHDyyR0qGjc1S8ERzSwS6bxySQgD3P3/zOwyAHffZmYdXaksTbZvh4cfbp4Z9M9/huPHHx868xOJMECcp0V8M2fm5TQiUoFySQgbzaw/YSAZMzsReLegUVW6zZth4cKQAGbPhtWroWtXOP10uOSSUDRu8OCCXHqXDe5T9O9fkEuKSJnIJSFcQihsd7CZPUSYGfSJgkZVid56C+bMCUlgwQLYtAn69g07iCUSMGYM7LFHrCHecEOslxeRmGVNCO6+zMw+AhwKGPC8u28teGSV4MUXm7uCHnww1BDaf3+46KKQBE47LZSTLhEqUyHSuaVNCGb2sTQvfdDMcPc/Fyim8tXYCEuXNi8Sa1rue/TRcPnlIQl86EOxbiLTv3/r6xC0GE1EMrUQxkXf9yYsTrsnev5RYDGghABhKui99za3BF5/PcwCOu00+NKXYPx4OPDAuKMEwv4H69bterxbNy1GE5EMCcHdLwQwsznAUHdfFT3fD/if4oRXotauDcXi6uvD9/XroXfvMA6QSIRxgb32ijvKXUyfHhY5t7T77uouEpHcBpVrmpJB5A3ggwWKp3StWBEWidXXw+LFoWjcPvvAZz4TksDIkWHlcDvU1YX6QtlKShTKmjXxXFdESksuCWGxmc0H/kCYevoZ4N6CRlUK3OHJJ5sXiS2Lavkddhh8/eshCQwfvlPRuPaoq4MLL2z9k3ux9O4d37VFpHTkMsvo4qgYXdM+yjPd/S+FDSsm27aF2UBNSeCVV8IA8EknwQ9+EJLAoYfm9ZLpunGKaePG7O8RkcqXywY586O9DSozCWzYEIrGJZOhaNyaNdC9e6gTNH16WCS2zz4Fu/yrrxbs1DlTMTsRgdw2yNlkZn3dvXJWJ//rX2GFcDIJixaF7SX32itUDJ0wIVQQLVI/ypAhoXp1nDpQGklEKkguYwhbgCfNbCE7b5Dz1YJFVQjPPdc8NfSRR8LH4gMPDNXeEomwl8Buufw58mvGjPjHECZNiu/aIlI6crkD3hl9la8pU+DGG8PjYcPg6qtDEjjyyFgXiUHzdM+4ZhlNmaIKpyISZN0gx8x6AB8gzDB60d23FCOw1rR7g5z580MZifHjQ+kIEZFOpMMb5JjZboSNcS4CGoAuwP5m9htgekfqGZnZtYSV0O8DLwIXuvva9p4vq9HanVNEJJtMk+ivBfYCDnT3Ye7+IeBgoB/w3x287kLgSHc/mrDhzmUdPJ+IiHRQpoQwFviSu69vOuDu64ApwNkduai7L3D3bdHTRwD144iIxCxTQnBvZYDB3bcTbZaTJxcB89K9aGaTzGyJmS1ZvXp1Hi9bGurqoKYmLHiuqQnPRUTikCkhPGNmn2950MzOA57LdmIzW2RmT7XylUh5z3RgG5D2NujuM9291t1rBw4cmO2yZaWuLkz5bGgIs2AbGsJzJQURiUPaWUZmNphQ4nozsJTQKjge6Amc6+4rO3Rhs/OBycBId9+Uy8+0e5ZRiaqpaX1RWnV1qJohIpIPHZ5lFN3wh5vZ6cARhN3S5rn73XkIbgzwLeAjuSaDSpSubEUplLMQkc4nl+J299C8OU6+/AzoDiy0sDDsEXefnOdrlLx0ZSuGDCl+LCIixa/VALj7B+K4bqmZMSOMGWxKaSP16qXdy0QkHh0r5i8dMnEizJwZxgzMwveZM7V7mYjEI5YWgjSbOFEJQERKg1oIIiICKCGIiEhECUFERAAlBBERiSghiIgIoIQQGxW1E5FSo2mnMWgqate0IK2pqB1oCqqIxEcthBhMn77z6mQIz6dPjyceERFQQoiFitqJSClSQohBuuJ1KmonInFSQojBjBmhiF0qFbUTkbgpIcSkZ8/mx/37q6idiMRPs4yKrOUMI4DNm+OLR0SkiVoIRaYZRiJSqmJJCGaI+i91AAALNUlEQVT2PTN7wsyWm9kCMxsURxxx0AwjESlVcbUQrnX3o939WGAO8N2Y4ig6zTASkVIVS0Jw93UpT3sDHkcccdAMIxEpVbGNIZjZDDNbAUwkQwvBzCaZ2RIzW7J69eriBVgg2jZTREqVuRfmw7mZLQL2beWl6e6eTHnfZUAPd78i2zlra2t9yZIleYxSRKTymdlSd6/N9r6CTTt191E5vvX3wJ1A1oQgIiKFE9cso0NSno4HnosjDhERaRbXwrRrzOxQoBFoACbHFIeIiERiSQju/vE4risiIulppbKIiABKCCIiElFCEBERQAlBREQiSggiIgIoIRRdXR3U1ECXLuF7XV3cEYmIBNogp4habo7T0BCeg2oZiUj81EIoIm2OIyKlTAmhiLQ5joiUMiWEIqmrC+MGrdHmOCJSCpQQiqBp7GD79l1f0+Y4IlIqNKhcYHV1cP75rSeDqiptjiMipUMthDxrmlZqFrqIzjuv9WQA0NioZCAipUMthDxqOa0022Z0GjsQkVKiFkIetTatNB2NHYhIqVFCyKNcp49q7EBESpESQh7l0gXUqxfcequSgYiUnlgTgpl9w8zczAbEGUe+zJgRbvjp9O+vloGIlK7YEoKZHQCcAVTMOt2JE8MNv7o6PK+qCt+rq+G22+Ctt5QMRKR0xTnL6EfApUAyxhjybuJE3fRFpDzF0kIws/HASnd/PIf3TjKzJWa2ZPXq1UWITkSkcypYQjCzRWb2VCtfCWA68N1czuPuM9291t1rBw4cWKhwO0R7HIhIJShYl5G7j2rtuJkdBRwIPG5mAPsDy8zsBHf/V6HiKRTtcSAilaLoXUbu/qS77+3uNe5eA7wGHFeOyQC0x4GIVA6tQ2inpm6ihobWX9ceByJSbmJPCFFL4a2448ik5RjB1KmhWyhdMgDVKRKR8hN7QiglrQ0ON40RNDSEYnUNDXDjjZlrFqlOkYiUI1U7jaQbHO7Zc9ebf6YqptXVIRloQFlEyk3FtxBynRKabnD47bdzv1Z1NbzyipKBiJSnim4htGVKaFsHgc12bimom0hEyl1FtxDaMiU03SBw//67Fqzr1QsmTw4tArPwXUXrRKTcVXQLId2n/taOz5ixc2sCwo3/hhvC4+nTw88NGaIxAhGpTBWdEIYMaX1qaGutgaYbfLobvxKAiFS6iu4yam1/gkx9/RMnhkHhxkYNDotI51PRCSF1fwL19YuIZFbRXUag/QlERHJV0S0EERHJnRKCiIgASggiIhJRQhAREUAJQUREIuaZSneWGDNbDWTYhaBoBgAlvYdDK8otZsVbeOUWc7nFC6UTc7W7Z92UvqwSQqkwsyXuXht3HG1RbjEr3sIrt5jLLV4ov5jVZSQiIoASgoiIRJQQ2mdm3AG0Q7nFrHgLr9xiLrd4ocxi1hiCiIgAaiGIiEhECUFERAAlhHYzs++Z2RNmttzMFpjZoLhjysTMrjWz56KY/2Jm/eKOKRsz+6SZPW1mjWZWslP3zGyMmT1vZi+Y2bfjjicbM7vZzN40s6fijiUXZnaAmd1rZs9G/x6mxR1TJmbWw8z+ZmaPR/FeFXdMudIYQjuZ2R7uvi56/FVgqLtPjjmstMzsTOAed99mZj8AcPdvxRxWRmZ2ONAI/BL4hrsviTmkXZhZFfAP4AzgNeAx4LPu/kysgWVgZqcBG4DfuvuRcceTjZntB+zn7svMbHdgKTChVP/GZmZAb3ffYGZdgQeBae7+SMyhZaUWQjs1JYNIb6CkM6u7L3D3bdHTR4D944wnF+7+rLs/H3ccWZwAvODuL7n7+8D/AomYY8rI3e8H1sQdR67cfZW7L4serweeBQbHG1V6HmyInnaNvkr6/tBECaEDzGyGma0AJgLfjTueNrgImBd3EBViMLAi5flrlPDNqtyZWQ3wIeDReCPJzMyqzGw58Caw0N1LOt4mSggZmNkiM3uqla8EgLtPd/cDgDrg4nijzR5v9J7pwDZCzLHLJeYSZ60cK4tPg+XGzPoAfwL+o0ULveS4+3Z3P5bQEj/BzEq+aw46wRaaHeHuo3J86++BO4ErChhOVtniNbPzgbHASC+RwaM2/I1L1WvAASnP9wdejymWihX1xf8JqHP3P8cdT67cfa2ZLQbGACU/iK8WQjuZ2SEpT8cDz8UVSy7MbAzwLWC8u2+KO54K8hhwiJkdaGbdgM8As2KOqaJEg7S/Bp519+vjjicbMxvYNIvPzHoCoyjx+0MTzTJqJzP7E3AoYRZMAzDZ3VfGG1V6ZvYC0B14Ozr0SCnPigIws3OBnwIDgbXAcncfHW9UuzKzs4EfA1XAze4+I+aQMjKzPwAjCKWZ3wCucPdfxxpUBmb2YeAB4EnC/28A33H3ufFFlZ6ZHQ3cSvj30AX4P3e/Ot6ocqOEICIigLqMREQkooQgIiKAEoKIiESUEEREBFBCEBGRiBKCxMLM+keVYpeb2b/MbGX0eK2ZFbVomZkdG00dbXo+vr1VS83sFTMbkL/o2nTtC1Kr7prZTWY2NO64pHwoIUgs3P1tdz82Wt5/I/Cj6PGxNM81zxszy7Qq/1hgR0Jw91nufk2+YyiCC4AdCcHdv1iqFUGlNCkhSCmqMrNfRbXkF0SrPTGzg83sLjNbamYPmNlh0fFqM7s72uvhbjMbEh2/xcyuN7N7gR+YWe9oL4DHzOzvZpaIVhdfDXw6aqF8Ovqk/bPoHPtY2D/i8ejr5Oh4fRTH02Y2KdsvZGYXmtk/zOy+6HdrOv8tZvaJlPdtiL73iX6XZWb2ZFNtJzOrsbAvwE5/n+gctUBd9Hv0NLPF1so+EmZ2noV6/cvN7JcWCrFVRbE8FV3vax347ydlSglBStEhwP+4+xGEFcofj47PBL7i7sOAbwA/j47/jFDb/2hC0b6fpJzrg8Aod/86MJ2wJ8TxwEeBawmlib8L3B61WG5vEctPgPvc/RjgOODp6PhFURy1wFfNrH+6X8ZCPf+rgFMI+yYMzeFvsAU4192Pi2K9Lirh0Orfx93/CCwBJka/x+Y0sRwOfBo4JWqRbSdU6z0WGOzuR7r7UcBvcohRKoyK20kpetndl0ePlwI1UaXLk4E7mu+LdI++nwR8LHr8O+CHKee6w923R4/PBMab2Tei5z2AIVliOR34PIQKlsC70fGvRqU1IBS3O4TmsiAtDQcWu/tqADO7nZCoMjHg+xY2s2kklNTeJ3ptl79PlnOlGgkMAx6L/o49CSWaZwMHmdlPCYUaF7ThnFIhlBCkFL2X8ng74abVBVgbfarNJrUey8aUx0b4NL3TpjtmNrwtwZnZCELBspPcfVNUzbJHG2JKtY2opR61ALpFxycSajgNc/etZvZKyjVa+/vkHD5wq7tftssLZscAo4EvA58i7JshnYi6jKQsRPXvXzazT0K4eUY3MIC/EqqMQriRPpjmNPOBrzR1vZjZh6Lj64Hd0/zM3cCU6P1VZrYH0Bd4J0oGhwEnZgn/UWBENLOqK/DJlNdeIXxih7DTWtfocV/gzSgZfBSoznKNbL9H6u/zCTPbO/qd9orGYAYAXdz9T8D/I3SPSSejhCDlZCLwBTN7nNCX37SJzleBC83sCeBzQLpN2L9HuOE+YWGD+e9Fx+8FhjYNKrf4mWnAR83sSUL3zBHAXcBu0fW+R9iSNC13XwVcCTwMLAKWpbz8K+AjZvY3QtdSU4umDqg1syXR751L+eRbgBubBpXTxPIMcDmwIIp/IbAfoUtqsYVdvm4BdmlBSOVTtVORIjOzC4Bad499lz2RVGohiIgIoBaCiIhE1EIQERFACUFERCJKCCIiAighiIhIRAlBREQA+P+kbyjH5EaRzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cf4a128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probplot(results.resid, dist='norm', plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observar que o Prob(Omnibus) e o Prob(JB) estavam dando zero, foi necessario fazer um proplot para verificar se os dados estavam seguindo uma normal. Apos perceber que os dados se aproximam de uma normal, temos maior seguranca no valor p e fazer analise a partir dele, como eliminar as variaveis com valores altos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datanova1[['Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.428</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   121.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>5.90e-262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:29:58</td>     <th>  Log-Likelihood:    </th> <td> -2145.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4320.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2262</td>      <th>  BIC:               </th> <td>   4406.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    1.7278</td> <td>    0.065</td> <td>   26.705</td> <td> 0.000</td> <td>    1.601</td> <td>    1.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.5517</td> <td>    0.048</td> <td>   11.465</td> <td> 0.000</td> <td>    0.457</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.5517</td> <td>    0.031</td> <td>   17.939</td> <td> 0.000</td> <td>    0.491</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.2722</td> <td>    0.626</td> <td>    3.629</td> <td> 0.000</td> <td>    1.044</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.5412</td> <td>    0.034</td> <td>   15.845</td> <td> 0.000</td> <td>    0.474</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.5400</td> <td>    0.031</td> <td>   17.683</td> <td> 0.000</td> <td>    0.480</td> <td>    0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.5161</td> <td>    0.032</td> <td>   16.031</td> <td> 0.000</td> <td>    0.453</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.4525</td> <td>    0.042</td> <td>   10.764</td> <td> 0.000</td> <td>    0.370</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.5248</td> <td>    0.035</td> <td>   15.106</td> <td> 0.000</td> <td>    0.457</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.4509</td> <td>    0.036</td> <td>   12.514</td> <td> 0.000</td> <td>    0.380</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    0.6743</td> <td>    0.035</td> <td>   19.396</td> <td> 0.000</td> <td>    0.606</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.4967</td> <td>    0.033</td> <td>   14.862</td> <td> 0.000</td> <td>    0.431</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.5547</td> <td>    0.038</td> <td>   14.446</td> <td> 0.000</td> <td>    0.479</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.4803</td> <td>    0.039</td> <td>   12.395</td> <td> 0.000</td> <td>    0.404</td> <td>    0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.5156</td> <td>    0.030</td> <td>   17.043</td> <td> 0.000</td> <td>    0.456</td> <td>    0.575</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>621.229</td> <th>  Durbin-Watson:     </th> <td>   1.939</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20884.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.611</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>17.786</td>  <th>  Cond. No.          </th> <td>    92.0</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.428\n",
       "Model:                            OLS   Adj. R-squared:                  0.425\n",
       "Method:                 Least Squares   F-statistic:                     121.0\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):          5.90e-262\n",
       "Time:                        10:29:58   Log-Likelihood:                -2145.2\n",
       "No. Observations:                2277   AIC:                             4320.\n",
       "Df Residuals:                    2262   BIC:                             4406.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.7278      0.065     26.705      0.000       1.601       1.855\n",
       "Aroused        0.5517      0.048     11.465      0.000       0.457       0.646\n",
       "Creative       0.5517      0.031     17.939      0.000       0.491       0.612\n",
       "Dry            2.2722      0.626      3.629      0.000       1.044       3.500\n",
       "Energetic      0.5412      0.034     15.845      0.000       0.474       0.608\n",
       "Euphoric       0.5400      0.031     17.683      0.000       0.480       0.600\n",
       "Focused        0.5161      0.032     16.031      0.000       0.453       0.579\n",
       "Giggly         0.4525      0.042     10.764      0.000       0.370       0.535\n",
       "Happy          0.5248      0.035     15.106      0.000       0.457       0.593\n",
       "Hungry         0.4509      0.036     12.514      0.000       0.380       0.522\n",
       "Relaxed        0.6743      0.035     19.396      0.000       0.606       0.742\n",
       "Sleepy         0.4967      0.033     14.862      0.000       0.431       0.562\n",
       "Talkative      0.5547      0.038     14.446      0.000       0.479       0.630\n",
       "Tingly         0.4803      0.039     12.395      0.000       0.404       0.556\n",
       "Uplifted       0.5156      0.030     17.043      0.000       0.456       0.575\n",
       "==============================================================================\n",
       "Omnibus:                      621.229   Durbin-Watson:                   1.939\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20884.032\n",
       "Skew:                          -0.611   Prob(JB):                         0.00\n",
       "Kurtosis:                      17.786   Cond. No.                         92.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto (sabores)\n",
    "results = regress1(X,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizadas as regresões, foi observado que o valor de R^2 estava baixo. eliminando as variaveis com valores \"p\" alto, continuou um valor baixo para R^2. Um p-value baixo permite rejeitar a hipótese H0 de que Bi = 0. Então, foi retirado da regressao a constante os o resultados estao mostrados a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressao sem a constante\n",
    "def regress(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['Tipo', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1355.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:29:59</td>     <th>  Log-Likelihood:    </th> <td> -2416.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4958.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2214</td>      <th>  BIC:               </th> <td>   5319.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    63</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>         <td>    0.0794</td> <td>    0.020</td> <td>    3.960</td> <td> 0.000</td> <td>    0.040</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.7661</td> <td>    0.057</td> <td>   13.433</td> <td> 0.000</td> <td>    0.654</td> <td>    0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.7724</td> <td>    0.038</td> <td>   20.287</td> <td> 0.000</td> <td>    0.698</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.8429</td> <td>    0.386</td> <td>    4.777</td> <td> 0.000</td> <td>    1.086</td> <td>    2.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.7460</td> <td>    0.042</td> <td>   17.610</td> <td> 0.000</td> <td>    0.663</td> <td>    0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.7409</td> <td>    0.039</td> <td>   19.166</td> <td> 0.000</td> <td>    0.665</td> <td>    0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.7231</td> <td>    0.040</td> <td>   18.110</td> <td> 0.000</td> <td>    0.645</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.6790</td> <td>    0.050</td> <td>   13.642</td> <td> 0.000</td> <td>    0.581</td> <td>    0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.7007</td> <td>    0.044</td> <td>   15.917</td> <td> 0.000</td> <td>    0.614</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.6846</td> <td>    0.044</td> <td>   15.735</td> <td> 0.000</td> <td>    0.599</td> <td>    0.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.8429</td> <td>    0.386</td> <td>    4.777</td> <td> 0.000</td> <td>    1.086</td> <td>    2.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.9393</td> <td>    0.044</td> <td>   21.532</td> <td> 0.000</td> <td>    0.854</td> <td>    1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.6951</td> <td>    0.042</td> <td>   16.631</td> <td> 0.000</td> <td>    0.613</td> <td>    0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.7512</td> <td>    0.047</td> <td>   16.094</td> <td> 0.000</td> <td>    0.660</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.7017</td> <td>    0.046</td> <td>   15.119</td> <td> 0.000</td> <td>    0.611</td> <td>    0.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.7253</td> <td>    0.038</td> <td>   19.087</td> <td> 0.000</td> <td>    0.651</td> <td>    0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2319</td> <td>    0.143</td> <td>    1.627</td> <td> 0.104</td> <td>   -0.048</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>    0.0060</td> <td>    0.187</td> <td>    0.032</td> <td> 0.975</td> <td>   -0.360</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.0762</td> <td>    0.257</td> <td>    0.297</td> <td> 0.766</td> <td>   -0.427</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2535</td> <td>    0.056</td> <td>    4.531</td> <td> 0.000</td> <td>    0.144</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1245</td> <td>    0.258</td> <td>   -0.482</td> <td> 0.630</td> <td>   -0.631</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.2323</td> <td>    0.075</td> <td>    3.115</td> <td> 0.002</td> <td>    0.086</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.1272</td> <td>    0.169</td> <td>    0.751</td> <td> 0.452</td> <td>   -0.205</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0842</td> <td>    0.105</td> <td>    0.801</td> <td> 0.423</td> <td>   -0.122</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.2505</td> <td>    0.126</td> <td>    1.995</td> <td> 0.046</td> <td>    0.004</td> <td>    0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.1359</td> <td>    0.298</td> <td>    0.457</td> <td> 0.648</td> <td>   -0.448</td> <td>    0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.2053</td> <td>    0.052</td> <td>    3.964</td> <td> 0.000</td> <td>    0.104</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.3686</td> <td>    0.153</td> <td>    2.412</td> <td> 0.016</td> <td>    0.069</td> <td>    0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.2147</td> <td>    0.060</td> <td>    3.581</td> <td> 0.000</td> <td>    0.097</td> <td>    0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1784</td> <td>    0.046</td> <td>    3.837</td> <td> 0.000</td> <td>    0.087</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2635</td> <td>    0.058</td> <td>    4.544</td> <td> 0.000</td> <td>    0.150</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0786</td> <td>    0.067</td> <td>    1.173</td> <td> 0.241</td> <td>   -0.053</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.2288</td> <td>    0.076</td> <td>    3.002</td> <td> 0.003</td> <td>    0.079</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1636</td> <td>    0.123</td> <td>    1.325</td> <td> 0.185</td> <td>   -0.079</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2863</td> <td>    0.135</td> <td>    2.129</td> <td> 0.033</td> <td>    0.023</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.2152</td> <td>    0.126</td> <td>    1.713</td> <td> 0.087</td> <td>   -0.031</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.2233</td> <td>    0.065</td> <td>    3.422</td> <td> 0.001</td> <td>    0.095</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2782</td> <td>    0.107</td> <td>    2.608</td> <td> 0.009</td> <td>    0.069</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1829</td> <td>    0.132</td> <td>    1.386</td> <td> 0.166</td> <td>   -0.076</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.4150</td> <td>    0.157</td> <td>    2.638</td> <td> 0.008</td> <td>    0.106</td> <td>    0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.2022</td> <td>    0.176</td> <td>    1.150</td> <td> 0.250</td> <td>   -0.142</td> <td>    0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3721</td> <td>    0.120</td> <td>    3.106</td> <td> 0.002</td> <td>    0.137</td> <td>    0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.2135</td> <td>    0.148</td> <td>    1.440</td> <td> 0.150</td> <td>   -0.077</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.2136</td> <td>    0.093</td> <td>    2.297</td> <td> 0.022</td> <td>    0.031</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.7887</td> <td>    0.295</td> <td>    2.677</td> <td> 0.007</td> <td>    0.211</td> <td>    1.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2450</td> <td>    0.418</td> <td>    0.586</td> <td> 0.558</td> <td>   -0.575</td> <td>    1.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.2728</td> <td>    0.101</td> <td>    2.692</td> <td> 0.007</td> <td>    0.074</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.2392</td> <td>    0.057</td> <td>    4.164</td> <td> 0.000</td> <td>    0.127</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.2114</td> <td>    0.121</td> <td>    1.754</td> <td> 0.080</td> <td>   -0.025</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0037</td> <td>    0.510</td> <td>    0.007</td> <td> 0.994</td> <td>   -0.997</td> <td>    1.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.2074</td> <td>    0.052</td> <td>    4.003</td> <td> 0.000</td> <td>    0.106</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1154</td> <td>    0.185</td> <td>    0.625</td> <td> 0.532</td> <td>   -0.247</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.2027</td> <td>    0.121</td> <td>    1.669</td> <td> 0.095</td> <td>   -0.036</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.2331</td> <td>    0.068</td> <td>    3.453</td> <td> 0.001</td> <td>    0.101</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2516</td> <td>    0.061</td> <td>    4.138</td> <td> 0.000</td> <td>    0.132</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1722</td> <td>    0.112</td> <td>    1.542</td> <td> 0.123</td> <td>   -0.047</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.2237</td> <td>    0.046</td> <td>    4.896</td> <td> 0.000</td> <td>    0.134</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.3273</td> <td>    0.273</td> <td>    1.199</td> <td> 0.231</td> <td>   -0.208</td> <td>    0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0861</td> <td>    0.177</td> <td>    0.486</td> <td> 0.627</td> <td>   -0.262</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0175</td> <td>    0.256</td> <td>   -0.068</td> <td> 0.946</td> <td>   -0.520</td> <td>    0.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0786</td> <td>    0.067</td> <td>    1.173</td> <td> 0.241</td> <td>   -0.053</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.2089</td> <td>    0.071</td> <td>    2.922</td> <td> 0.004</td> <td>    0.069</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1887</td> <td>    0.134</td> <td>    1.410</td> <td> 0.159</td> <td>   -0.074</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.2193</td> <td>    0.276</td> <td>    0.796</td> <td> 0.426</td> <td>   -0.321</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.1182</td> <td>    0.060</td> <td>    1.968</td> <td> 0.049</td> <td>    0.000</td> <td>    0.236</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1415.144</td> <th>  Durbin-Watson:     </th> <td>   1.966</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>46498.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.395</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>24.614</td>  <th>  Cond. No.          </th> <td>1.39e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.975\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     1355.\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:29:59   Log-Likelihood:                -2416.1\n",
       "No. Observations:                2277   AIC:                             4958.\n",
       "Df Residuals:                    2214   BIC:                             5319.\n",
       "Df Model:                          63                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Tipo             0.0794      0.020      3.960      0.000       0.040       0.119\n",
       "Aroused          0.7661      0.057     13.433      0.000       0.654       0.878\n",
       "Creative         0.7724      0.038     20.287      0.000       0.698       0.847\n",
       "Dry              1.8429      0.386      4.777      0.000       1.086       2.599\n",
       "Energetic        0.7460      0.042     17.610      0.000       0.663       0.829\n",
       "Euphoric         0.7409      0.039     19.166      0.000       0.665       0.817\n",
       "Focused          0.7231      0.040     18.110      0.000       0.645       0.801\n",
       "Giggly           0.6790      0.050     13.642      0.000       0.581       0.777\n",
       "Happy            0.7007      0.044     15.917      0.000       0.614       0.787\n",
       "Hungry           0.6846      0.044     15.735      0.000       0.599       0.770\n",
       "Mouth            1.8429      0.386      4.777      0.000       1.086       2.599\n",
       "Relaxed          0.9393      0.044     21.532      0.000       0.854       1.025\n",
       "Sleepy           0.6951      0.042     16.631      0.000       0.613       0.777\n",
       "Talkative        0.7512      0.047     16.094      0.000       0.660       0.843\n",
       "Tingly           0.7017      0.046     15.119      0.000       0.611       0.793\n",
       "Uplifted         0.7253      0.038     19.087      0.000       0.651       0.800\n",
       "Ammonia          0.2319      0.143      1.627      0.104      -0.048       0.512\n",
       "Apple            0.0060      0.187      0.032      0.975      -0.360       0.372\n",
       "Apricot          0.0762      0.257      0.297      0.766      -0.427       0.579\n",
       "Berry            0.2535      0.056      4.531      0.000       0.144       0.363\n",
       "Blue            -0.1245      0.258     -0.482      0.630      -0.631       0.382\n",
       "Blueberry        0.2323      0.075      3.115      0.002       0.086       0.378\n",
       "Butter           0.1272      0.169      0.751      0.452      -0.205       0.459\n",
       "Cheese           0.0842      0.105      0.801      0.423      -0.122       0.290\n",
       "Chemical         0.2505      0.126      1.995      0.046       0.004       0.497\n",
       "Chestnut         0.1359      0.298      0.457      0.648      -0.448       0.719\n",
       "Citrus           0.2053      0.052      3.964      0.000       0.104       0.307\n",
       "Coffee           0.3686      0.153      2.412      0.016       0.069       0.668\n",
       "Diesel           0.2147      0.060      3.581      0.000       0.097       0.332\n",
       "Earthy           0.1784      0.046      3.837      0.000       0.087       0.270\n",
       "Flowery          0.2635      0.058      4.544      0.000       0.150       0.377\n",
       "Fruit            0.0786      0.067      1.173      0.241      -0.053       0.210\n",
       "Grape            0.2288      0.076      3.002      0.003       0.079       0.378\n",
       "Grapefruit       0.1636      0.123      1.325      0.185      -0.079       0.406\n",
       "Honey            0.2863      0.135      2.129      0.033       0.023       0.550\n",
       "Lavender         0.2152      0.126      1.713      0.087      -0.031       0.462\n",
       "Lemon            0.2233      0.065      3.422      0.001       0.095       0.351\n",
       "Lime             0.2782      0.107      2.608      0.009       0.069       0.487\n",
       "Mango            0.1829      0.132      1.386      0.166      -0.076       0.442\n",
       "Menthol          0.4150      0.157      2.638      0.008       0.106       0.723\n",
       "Mint             0.2022      0.176      1.150      0.250      -0.142       0.547\n",
       "Minty            0.3721      0.120      3.106      0.002       0.137       0.607\n",
       "Nutty            0.2135      0.148      1.440      0.150      -0.077       0.504\n",
       "Orange           0.2136      0.093      2.297      0.022       0.031       0.396\n",
       "Peach            0.7887      0.295      2.677      0.007       0.211       1.367\n",
       "Pear             0.2450      0.418      0.586      0.558      -0.575       1.065\n",
       "Pepper           0.2728      0.101      2.692      0.007       0.074       0.471\n",
       "Pine             0.2392      0.057      4.164      0.000       0.127       0.352\n",
       "Pineapple        0.2114      0.121      1.754      0.080      -0.025       0.448\n",
       "Plum             0.0037      0.510      0.007      0.994      -0.997       1.004\n",
       "Pungent          0.2074      0.052      4.003      0.000       0.106       0.309\n",
       "Rose             0.1154      0.185      0.625      0.532      -0.247       0.477\n",
       "Sage             0.2027      0.121      1.669      0.095      -0.036       0.441\n",
       "Skunk            0.2331      0.068      3.453      0.001       0.101       0.365\n",
       "Spicy/Herbal     0.2516      0.061      4.138      0.000       0.132       0.371\n",
       "Strawberry       0.1722      0.112      1.542      0.123      -0.047       0.391\n",
       "Sweet            0.2237      0.046      4.896      0.000       0.134       0.313\n",
       "Tar              0.3273      0.273      1.199      0.231      -0.208       0.863\n",
       "Tea              0.0861      0.177      0.486      0.627      -0.262       0.434\n",
       "Tobacco         -0.0175      0.256     -0.068      0.946      -0.520       0.485\n",
       "Tree             0.0786      0.067      1.173      0.241      -0.053       0.210\n",
       "Tropical         0.2089      0.071      2.922      0.004       0.069       0.349\n",
       "Vanilla          0.1887      0.134      1.410      0.159      -0.074       0.451\n",
       "Violet           0.2193      0.276      0.796      0.426      -0.321       0.760\n",
       "Woody            0.1182      0.060      1.968      0.049       0.000       0.236\n",
       "==============================================================================\n",
       "Omnibus:                     1415.144   Durbin-Watson:                   1.966\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46498.494\n",
       "Skew:                           2.395   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.614   Cond. No.                     1.39e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.62e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c19159b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probplot(results.resid, dist='norm', plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos obserevar que ao retirar a constante, o numero de residuos no probplot diminuiu, \n",
    "deixando a reta mais proxima de uma normal. O resultado foi observado no valor do r^2 que aumentou bruscamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna \"tipo\" foi retirada, pois observamos que para os 3 diferentes tipos hibrida, sativa, indica o coeficiente era o mesmo, por isso usamos como se o \"tipo\" fosse sempre 1 no np.dot ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = datanova1[[\n",
    "        'Tipo','Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted',  'Peach']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5301.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:01</td>     <th>  Log-Likelihood:    </th> <td> -2446.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4926.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2261</td>      <th>  BIC:               </th> <td>   5017.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>      <td>    0.0800</td> <td>    0.020</td> <td>    4.047</td> <td> 0.000</td> <td>    0.041</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.8890</td> <td>    0.053</td> <td>   16.771</td> <td> 0.000</td> <td>    0.785</td> <td>    0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.8924</td> <td>    0.032</td> <td>   28.025</td> <td> 0.000</td> <td>    0.830</td> <td>    0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.0000</td> <td>    0.356</td> <td>    5.624</td> <td> 0.000</td> <td>    1.303</td> <td>    2.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.8690</td> <td>    0.037</td> <td>   23.639</td> <td> 0.000</td> <td>    0.797</td> <td>    0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.8669</td> <td>    0.032</td> <td>   27.233</td> <td> 0.000</td> <td>    0.804</td> <td>    0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.8402</td> <td>    0.034</td> <td>   24.668</td> <td> 0.000</td> <td>    0.773</td> <td>    0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.7922</td> <td>    0.046</td> <td>   17.336</td> <td> 0.000</td> <td>    0.703</td> <td>    0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.8304</td> <td>    0.037</td> <td>   22.167</td> <td> 0.000</td> <td>    0.757</td> <td>    0.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.7902</td> <td>    0.038</td> <td>   20.565</td> <td> 0.000</td> <td>    0.715</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>     <td>    2.0000</td> <td>    0.356</td> <td>    5.624</td> <td> 0.000</td> <td>    1.303</td> <td>    2.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    1.0807</td> <td>    0.036</td> <td>   30.101</td> <td> 0.000</td> <td>    1.010</td> <td>    1.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.8061</td> <td>    0.036</td> <td>   22.392</td> <td> 0.000</td> <td>    0.735</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.8814</td> <td>    0.042</td> <td>   21.220</td> <td> 0.000</td> <td>    0.800</td> <td>    0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.8150</td> <td>    0.042</td> <td>   19.486</td> <td> 0.000</td> <td>    0.733</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.8443</td> <td>    0.031</td> <td>   26.836</td> <td> 0.000</td> <td>    0.783</td> <td>    0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>     <td>    0.6085</td> <td>    0.292</td> <td>    2.087</td> <td> 0.037</td> <td>    0.037</td> <td>    1.180</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1383.759</td> <th>  Durbin-Watson:     </th> <td>   1.970</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>48420.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.295</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>25.120</td>  <th>  Cond. No.          </th> <td>8.95e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.974\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     5301.\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:30:01   Log-Likelihood:                -2446.9\n",
       "No. Observations:                2277   AIC:                             4926.\n",
       "Df Residuals:                    2261   BIC:                             5017.\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Tipo           0.0800      0.020      4.047      0.000       0.041       0.119\n",
       "Aroused        0.8890      0.053     16.771      0.000       0.785       0.993\n",
       "Creative       0.8924      0.032     28.025      0.000       0.830       0.955\n",
       "Dry            2.0000      0.356      5.624      0.000       1.303       2.697\n",
       "Energetic      0.8690      0.037     23.639      0.000       0.797       0.941\n",
       "Euphoric       0.8669      0.032     27.233      0.000       0.804       0.929\n",
       "Focused        0.8402      0.034     24.668      0.000       0.773       0.907\n",
       "Giggly         0.7922      0.046     17.336      0.000       0.703       0.882\n",
       "Happy          0.8304      0.037     22.167      0.000       0.757       0.904\n",
       "Hungry         0.7902      0.038     20.565      0.000       0.715       0.866\n",
       "Mouth          2.0000      0.356      5.624      0.000       1.303       2.697\n",
       "Relaxed        1.0807      0.036     30.101      0.000       1.010       1.151\n",
       "Sleepy         0.8061      0.036     22.392      0.000       0.735       0.877\n",
       "Talkative      0.8814      0.042     21.220      0.000       0.800       0.963\n",
       "Tingly         0.8150      0.042     19.486      0.000       0.733       0.897\n",
       "Uplifted       0.8443      0.031     26.836      0.000       0.783       0.906\n",
       "Peach          0.6085      0.292      2.087      0.037       0.037       1.180\n",
       "==============================================================================\n",
       "Omnibus:                     1383.759   Durbin-Watson:                   1.970\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            48420.841\n",
       "Skew:                           2.295   Prob(JB):                         0.00\n",
       "Kurtosis:                      25.120   Cond. No.                     8.95e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.2e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto\n",
    "results = regress(xx,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos a retirada dos valores de \"p\" alto, ficamos com 15 variaveis, as quais estao citadas a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo         0.079975\n",
       "Aroused      0.889033\n",
       "Creative     0.892356\n",
       "Dry          2.000000\n",
       "Energetic    0.868954\n",
       "Euphoric     0.866872\n",
       "Focused      0.840199\n",
       "Giggly       0.792231\n",
       "Happy        0.830412\n",
       "Hungry       0.790244\n",
       "Mouth        2.000000\n",
       "Relaxed      1.080704\n",
       "Sleepy       0.806068\n",
       "Talkative    0.881382\n",
       "Tingly       0.814972\n",
       "Uplifted     0.844328\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variaveis = results.params[[ 'Tipo','Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]\n",
    "Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variaveis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-141ac61f3d60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualização do peso de cada variável na regressão linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mVariaveis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Variaveis' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualização do peso de cada variável na regressão linear\n",
    "Variaveis.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ao rodar o programa a seguir, pode-se consultar qual seria a nota de uma strain a partir de 5 efeitos escolhidos pelo usuario. A nota vai de 0 a 5, sendo 5 uma qualidade boa e 0 uma ruim.  O programa funciona da seguinte maneira, os efeitos vao aparecendo e o usuario escolhe 1 para os efeitos desejados ou 0 para os indesejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os efeitos que podem ser escolhidos sāo: ['Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric', 'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy', 'Talkative', 'Tingly', 'Uplifted']\n",
      "Aroused - 1\n",
      "Creative - 0\n",
      "Dry - 1\n",
      "Energetic - 0\n",
      "Euphoric - 1\n",
      "Focused - 1\n",
      "Giggly - 0\n",
      "Happy - 1\n",
      "Hungry - 0\n",
      "Mouth - 0\n",
      "Relaxed - 0\n",
      "Sleepy - 0\n",
      "Talkative - 0\n",
      "Tingly - 0\n",
      "Uplifted - 0\n",
      "Os efeitos que você escolheu deixam a sua strain com uma nota aproximadamente igual a 5.51\n"
     ]
    }
   ],
   "source": [
    "lista = [ 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']\n",
    "print(\"os efeitos que podem ser escolhidos sāo: {}\".format(lista))\n",
    "lista_final = [1,]\n",
    "i=1\n",
    "while i <= 15:\n",
    "    for e in lista:\n",
    "        ef = int(input(\"{} - \".format(e)))\n",
    "        if ef > 1:\n",
    "            print(\"Digite 1 para efeito desejado ou 0 para indesejado \")\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        if sum(lista_final)== 6 and ef == 1:\n",
    "            print('Você ja escolheu os 5 efeitos')\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        lista_final.append(ef)\n",
    "        i+=1\n",
    "    \n",
    "nota_final = np.dot(Variaveis, lista_final)\n",
    "print('Os efeitos que você escolheu deixam a sua strain com uma nota aproximadamente igual a {:.2f}'.format(nota_final))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusāo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Tendo em vista que a classificação dos diferentes strains leva em conta as sensações do usuário, a análise deveria se embasar naquilo que apesar de subjetivo, pudesse ser perceptível por diversos usuários. Dessa forma, avaliar sabores, como constatamos pela análise não seria um bom viés, por ser extremamente subjetivo, cada usuário teria uma preferência diferente.</p>\n",
    "\n",
    "Na criação de novas strains, por meio da manipulação de duas ou mais já existentes, leva-se em consideração os índices de THC e CBD de cada. A proporção de tais valores é fator limitante para a criação de novas strains com efeitos desejados. Portanto, saber quais efeitos se deseja obter, tendo em vista seu impacto individual na avaliação final dos usuários contribui para determinar a proporção de THC e CBD. É importante ressaltar que o grau do efeito, não apenas se ele existe ou não, contribui para a nota (fonte), fator que poder ter diminuído a acurácia de nosso teste por não termos dados. Por outro lado, pode-se afirmar que, no desenvolvimento de uma nova strain, focar na causa mais intensa daqueles efeitos que possuem maior coeficiente em nossa regressão (como Dry, Mouth, Aroused, Energetic) pode culminar para uma melhor avaliação dos usuários também, pois são efeitos mais valorizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separaçāo de tarefas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trabalho foi praticamente feito igualmente pelos dois integrantes do grupo, selecao do tema, joins do dataset, regressāo e o programa final que calcula a nota. O Lucas acabou focando na parte da conclusāo enquanto o Gianlucca focou na parte da limpeza e esclarecimento do codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
