{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># **Ciência dos Dados** <font color=purple>- Projeto 3</font>\n",
    "   #### <font color=grey> <p>Gianlucca de La Torre Napolitano </p> <p>Lucas Nicascio dos Santos</p> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação do peso de características a serem destacadas na fabricação da maconha e seus impactos na avaliação final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O projeto visa a análise de características presentes na Maconha como seus efeitos, sabor e tipo de forma a prever quais os fatores devem ser mais focados na fabricação de forma a obter uma ótima avaliação pelo público, tendo em vista que as características podem ser ajustadas pelas proporções de THC (Tetrahidrocanabinol) e CBD (Canabidiol) (não aprofundados nesse projeto) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente é necessário ler o Dataset \"Cannabis Strains\" obtido na plataforma Kaggle, bem como criar um Data Frame ábil para análise, pois contém variáveis qualitativas e quantitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import beta, probplot\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos arquivos em .csv e eliminação dos valores nulos do DataFrame \n",
    "df = pd.read_csv('cannabis.csv')\n",
    "data = df.dropna(how = 'any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classificação dos valores em \"Type\" em colunas de 0 e 1 para equivalência de variáveis qualitativas em quantitativas\n",
    "\n",
    "tipo = np.array(data.Type)\n",
    "label_encoder = LabelEncoder()\n",
    "Type_quan = label_encoder.fit_transform(tipo)\n",
    "Type_quan\n",
    "data = data.assign(Tipo = Type_quan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Effects\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "efeitos = data['Effects'].str.get_dummies(sep=',')\n",
    "efeitos = efeitos.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "data_nova = data.join(efeitos, how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação dos valores em \"Flavours\" em colunas de 0 e 1 e eliminação de valores \"None\" \n",
    "sabores = data['Flavor'].str.get_dummies(sep=',')\n",
    "sabores = sabores.drop(\"None\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos DataFrames\n",
    "datanova = data_nova.join(sabores, how = 'inner')\n",
    "#datanova0 = datanova.join(tipo,how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de colunas não mais necessárias do DataFrame\n",
    "datanova1 = datanova.drop(['Effects','Flavor','Type','Strain','Description'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress1(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinação das variáveis a serem utilizadas na regressão. A variável x foi separada de duas formas para testarmos a hipótese de que os sabores podem não ter um efeito significativo na regressão, pois são avaliados de forma subjetiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['Tipo', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n",
    "X = datanova1[['Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.427</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>1.02e-232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:53:39</td>     <th>  Log-Likelihood:    </th> <td> -2115.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4359.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2213</td>      <th>  BIC:               </th> <td>   4726.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    63</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    1.6989</td> <td>    0.066</td> <td>   25.856</td> <td> 0.000</td> <td>    1.570</td> <td>    1.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>         <td>    0.0022</td> <td>    0.018</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.033</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.4591</td> <td>    0.051</td> <td>    8.934</td> <td> 0.000</td> <td>    0.358</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.4616</td> <td>    0.035</td> <td>   13.014</td> <td> 0.000</td> <td>    0.392</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.0578</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.4491</td> <td>    0.039</td> <td>   11.553</td> <td> 0.000</td> <td>    0.373</td> <td>    0.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.4446</td> <td>    0.036</td> <td>   12.431</td> <td> 0.000</td> <td>    0.374</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.4285</td> <td>    0.037</td> <td>   11.642</td> <td> 0.000</td> <td>    0.356</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.3655</td> <td>    0.045</td> <td>    8.072</td> <td> 0.000</td> <td>    0.277</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.4258</td> <td>    0.040</td> <td>   10.639</td> <td> 0.000</td> <td>    0.347</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.3728</td> <td>    0.040</td> <td>    9.320</td> <td> 0.000</td> <td>    0.294</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.0578</td> <td>    0.340</td> <td>    3.116</td> <td> 0.002</td> <td>    0.392</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.5692</td> <td>    0.041</td> <td>   13.942</td> <td> 0.000</td> <td>    0.489</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.4123</td> <td>    0.038</td> <td>   10.782</td> <td> 0.000</td> <td>    0.337</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.4530</td> <td>    0.043</td> <td>   10.658</td> <td> 0.000</td> <td>    0.370</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.3969</td> <td>    0.042</td> <td>    9.370</td> <td> 0.000</td> <td>    0.314</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.4256</td> <td>    0.035</td> <td>   12.069</td> <td> 0.000</td> <td>    0.356</td> <td>    0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2174</td> <td>    0.125</td> <td>    1.740</td> <td> 0.082</td> <td>   -0.028</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>   -0.0948</td> <td>    0.164</td> <td>   -0.579</td> <td> 0.563</td> <td>   -0.416</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.1051</td> <td>    0.225</td> <td>    0.467</td> <td> 0.640</td> <td>   -0.336</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2103</td> <td>    0.049</td> <td>    4.287</td> <td> 0.000</td> <td>    0.114</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1263</td> <td>    0.227</td> <td>   -0.557</td> <td> 0.577</td> <td>   -0.571</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.1744</td> <td>    0.065</td> <td>    2.668</td> <td> 0.008</td> <td>    0.046</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.0985</td> <td>    0.148</td> <td>    0.664</td> <td> 0.507</td> <td>   -0.193</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0446</td> <td>    0.092</td> <td>    0.484</td> <td> 0.629</td> <td>   -0.136</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.1902</td> <td>    0.110</td> <td>    1.728</td> <td> 0.084</td> <td>   -0.026</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.0429</td> <td>    0.261</td> <td>    0.164</td> <td> 0.869</td> <td>   -0.469</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.1615</td> <td>    0.045</td> <td>    3.556</td> <td> 0.000</td> <td>    0.072</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.2961</td> <td>    0.134</td> <td>    2.210</td> <td> 0.027</td> <td>    0.033</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.1598</td> <td>    0.053</td> <td>    3.038</td> <td> 0.002</td> <td>    0.057</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1425</td> <td>    0.041</td> <td>    3.495</td> <td> 0.000</td> <td>    0.063</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2044</td> <td>    0.051</td> <td>    4.018</td> <td> 0.000</td> <td>    0.105</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.1933</td> <td>    0.067</td> <td>    2.892</td> <td> 0.004</td> <td>    0.062</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1318</td> <td>    0.108</td> <td>    1.218</td> <td> 0.223</td> <td>   -0.080</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2271</td> <td>    0.118</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.004</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.1748</td> <td>    0.110</td> <td>    1.587</td> <td> 0.113</td> <td>   -0.041</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.1697</td> <td>    0.057</td> <td>    2.965</td> <td> 0.003</td> <td>    0.057</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2570</td> <td>    0.094</td> <td>    2.748</td> <td> 0.006</td> <td>    0.074</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1518</td> <td>    0.116</td> <td>    1.313</td> <td> 0.189</td> <td>   -0.075</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.3415</td> <td>    0.138</td> <td>    2.476</td> <td> 0.013</td> <td>    0.071</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.1779</td> <td>    0.154</td> <td>    1.155</td> <td> 0.248</td> <td>   -0.124</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3271</td> <td>    0.105</td> <td>    3.114</td> <td> 0.002</td> <td>    0.121</td> <td>    0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.1310</td> <td>    0.130</td> <td>    1.007</td> <td> 0.314</td> <td>   -0.124</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.1755</td> <td>    0.082</td> <td>    2.153</td> <td> 0.031</td> <td>    0.016</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.4743</td> <td>    0.259</td> <td>    1.834</td> <td> 0.067</td> <td>   -0.033</td> <td>    0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2177</td> <td>    0.366</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.501</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.1972</td> <td>    0.089</td> <td>    2.220</td> <td> 0.027</td> <td>    0.023</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.1902</td> <td>    0.050</td> <td>    3.775</td> <td> 0.000</td> <td>    0.091</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.1843</td> <td>    0.106</td> <td>    1.744</td> <td> 0.081</td> <td>   -0.023</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0255</td> <td>    0.447</td> <td>    0.057</td> <td> 0.954</td> <td>   -0.851</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.1644</td> <td>    0.045</td> <td>    3.617</td> <td> 0.000</td> <td>    0.075</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1004</td> <td>    0.162</td> <td>    0.621</td> <td> 0.535</td> <td>   -0.217</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.1884</td> <td>    0.107</td> <td>    1.769</td> <td> 0.077</td> <td>   -0.020</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.1866</td> <td>    0.059</td> <td>    3.152</td> <td> 0.002</td> <td>    0.070</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2020</td> <td>    0.053</td> <td>    3.788</td> <td> 0.000</td> <td>    0.097</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1297</td> <td>    0.098</td> <td>    1.325</td> <td> 0.185</td> <td>   -0.062</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.1798</td> <td>    0.040</td> <td>    4.485</td> <td> 0.000</td> <td>    0.101</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.2829</td> <td>    0.239</td> <td>    1.182</td> <td> 0.237</td> <td>   -0.186</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0562</td> <td>    0.155</td> <td>    0.361</td> <td> 0.718</td> <td>   -0.249</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0468</td> <td>    0.225</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.487</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0719</td> <td>    0.059</td> <td>    1.223</td> <td> 0.221</td> <td>   -0.043</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.1831</td> <td>    0.063</td> <td>    2.922</td> <td> 0.004</td> <td>    0.060</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1464</td> <td>    0.117</td> <td>    1.248</td> <td> 0.212</td> <td>   -0.084</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.1789</td> <td>    0.242</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.295</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.0861</td> <td>    0.053</td> <td>    1.636</td> <td> 0.102</td> <td>   -0.017</td> <td>    0.189</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>557.472</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18573.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.454</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.962</td>  <th>  Cond. No.          </th> <td>1.15e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.443\n",
       "Model:                            OLS   Adj. R-squared:                  0.427\n",
       "Method:                 Least Squares   F-statistic:                     27.92\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):          1.02e-232\n",
       "Time:                        08:53:39   Log-Likelihood:                -2115.6\n",
       "No. Observations:                2277   AIC:                             4359.\n",
       "Df Residuals:                    2213   BIC:                             4726.\n",
       "Df Model:                          63                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            1.6989      0.066     25.856      0.000       1.570       1.828\n",
       "Tipo             0.0022      0.018      0.125      0.901      -0.033       0.037\n",
       "Aroused          0.4591      0.051      8.934      0.000       0.358       0.560\n",
       "Creative         0.4616      0.035     13.014      0.000       0.392       0.531\n",
       "Dry              1.0578      0.340      3.116      0.002       0.392       1.724\n",
       "Energetic        0.4491      0.039     11.553      0.000       0.373       0.525\n",
       "Euphoric         0.4446      0.036     12.431      0.000       0.374       0.515\n",
       "Focused          0.4285      0.037     11.642      0.000       0.356       0.501\n",
       "Giggly           0.3655      0.045      8.072      0.000       0.277       0.454\n",
       "Happy            0.4258      0.040     10.639      0.000       0.347       0.504\n",
       "Hungry           0.3728      0.040      9.320      0.000       0.294       0.451\n",
       "Mouth            1.0578      0.340      3.116      0.002       0.392       1.724\n",
       "Relaxed          0.5692      0.041     13.942      0.000       0.489       0.649\n",
       "Sleepy           0.4123      0.038     10.782      0.000       0.337       0.487\n",
       "Talkative        0.4530      0.043     10.658      0.000       0.370       0.536\n",
       "Tingly           0.3969      0.042      9.370      0.000       0.314       0.480\n",
       "Uplifted         0.4256      0.035     12.069      0.000       0.356       0.495\n",
       "Ammonia          0.2174      0.125      1.740      0.082      -0.028       0.463\n",
       "Apple           -0.0948      0.164     -0.579      0.563      -0.416       0.226\n",
       "Apricot          0.1051      0.225      0.467      0.640      -0.336       0.546\n",
       "Berry            0.2103      0.049      4.287      0.000       0.114       0.307\n",
       "Blue            -0.1263      0.227     -0.557      0.577      -0.571       0.318\n",
       "Blueberry        0.1744      0.065      2.668      0.008       0.046       0.303\n",
       "Butter           0.0985      0.148      0.664      0.507      -0.193       0.390\n",
       "Cheese           0.0446      0.092      0.484      0.629      -0.136       0.225\n",
       "Chemical         0.1902      0.110      1.728      0.084      -0.026       0.406\n",
       "Chestnut         0.0429      0.261      0.164      0.869      -0.469       0.554\n",
       "Citrus           0.1615      0.045      3.556      0.000       0.072       0.251\n",
       "Coffee           0.2961      0.134      2.210      0.027       0.033       0.559\n",
       "Diesel           0.1598      0.053      3.038      0.002       0.057       0.263\n",
       "Earthy           0.1425      0.041      3.495      0.000       0.063       0.222\n",
       "Flowery          0.2044      0.051      4.018      0.000       0.105       0.304\n",
       "Fruit            0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Grape            0.1933      0.067      2.892      0.004       0.062       0.324\n",
       "Grapefruit       0.1318      0.108      1.218      0.223      -0.080       0.344\n",
       "Honey            0.2271      0.118      1.926      0.054      -0.004       0.458\n",
       "Lavender         0.1748      0.110      1.587      0.113      -0.041       0.391\n",
       "Lemon            0.1697      0.057      2.965      0.003       0.057       0.282\n",
       "Lime             0.2570      0.094      2.748      0.006       0.074       0.440\n",
       "Mango            0.1518      0.116      1.313      0.189      -0.075       0.379\n",
       "Menthol          0.3415      0.138      2.476      0.013       0.071       0.612\n",
       "Mint             0.1779      0.154      1.155      0.248      -0.124       0.480\n",
       "Minty            0.3271      0.105      3.114      0.002       0.121       0.533\n",
       "Nutty            0.1310      0.130      1.007      0.314      -0.124       0.386\n",
       "Orange           0.1755      0.082      2.153      0.031       0.016       0.335\n",
       "Peach            0.4743      0.259      1.834      0.067      -0.033       0.981\n",
       "Pear             0.2177      0.366      0.594      0.553      -0.501       0.936\n",
       "Pepper           0.1972      0.089      2.220      0.027       0.023       0.371\n",
       "Pine             0.1902      0.050      3.775      0.000       0.091       0.289\n",
       "Pineapple        0.1843      0.106      1.744      0.081      -0.023       0.392\n",
       "Plum             0.0255      0.447      0.057      0.954      -0.851       0.902\n",
       "Pungent          0.1644      0.045      3.617      0.000       0.075       0.254\n",
       "Rose             0.1004      0.162      0.621      0.535      -0.217       0.418\n",
       "Sage             0.1884      0.107      1.769      0.077      -0.020       0.397\n",
       "Skunk            0.1866      0.059      3.152      0.002       0.070       0.303\n",
       "Spicy/Herbal     0.2020      0.053      3.788      0.000       0.097       0.307\n",
       "Strawberry       0.1297      0.098      1.325      0.185      -0.062       0.322\n",
       "Sweet            0.1798      0.040      4.485      0.000       0.101       0.258\n",
       "Tar              0.2829      0.239      1.182      0.237      -0.186       0.752\n",
       "Tea              0.0562      0.155      0.361      0.718      -0.249       0.361\n",
       "Tobacco         -0.0468      0.225     -0.208      0.835      -0.487       0.394\n",
       "Tree             0.0719      0.059      1.223      0.221      -0.043       0.187\n",
       "Tropical         0.1831      0.063      2.922      0.004       0.060       0.306\n",
       "Vanilla          0.1464      0.117      1.248      0.212      -0.084       0.376\n",
       "Violet           0.1789      0.242      0.741      0.459      -0.295       0.653\n",
       "Woody            0.0861      0.053      1.636      0.102      -0.017       0.189\n",
       "==============================================================================\n",
       "Omnibus:                      557.472   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18573.235\n",
       "Skew:                          -0.454   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.962   Cond. No.                     1.15e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.29e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress1(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.428</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   121.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>5.90e-262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:45</td>     <th>  Log-Likelihood:    </th> <td> -2145.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4320.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2262</td>      <th>  BIC:               </th> <td>   4406.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    1.7278</td> <td>    0.065</td> <td>   26.705</td> <td> 0.000</td> <td>    1.601</td> <td>    1.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.5517</td> <td>    0.048</td> <td>   11.465</td> <td> 0.000</td> <td>    0.457</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.5517</td> <td>    0.031</td> <td>   17.939</td> <td> 0.000</td> <td>    0.491</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.2722</td> <td>    0.626</td> <td>    3.629</td> <td> 0.000</td> <td>    1.044</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.5412</td> <td>    0.034</td> <td>   15.845</td> <td> 0.000</td> <td>    0.474</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.5400</td> <td>    0.031</td> <td>   17.683</td> <td> 0.000</td> <td>    0.480</td> <td>    0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.5161</td> <td>    0.032</td> <td>   16.031</td> <td> 0.000</td> <td>    0.453</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.4525</td> <td>    0.042</td> <td>   10.764</td> <td> 0.000</td> <td>    0.370</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.5248</td> <td>    0.035</td> <td>   15.106</td> <td> 0.000</td> <td>    0.457</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.4509</td> <td>    0.036</td> <td>   12.514</td> <td> 0.000</td> <td>    0.380</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    0.6743</td> <td>    0.035</td> <td>   19.396</td> <td> 0.000</td> <td>    0.606</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.4967</td> <td>    0.033</td> <td>   14.862</td> <td> 0.000</td> <td>    0.431</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.5547</td> <td>    0.038</td> <td>   14.446</td> <td> 0.000</td> <td>    0.479</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.4803</td> <td>    0.039</td> <td>   12.395</td> <td> 0.000</td> <td>    0.404</td> <td>    0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.5156</td> <td>    0.030</td> <td>   17.043</td> <td> 0.000</td> <td>    0.456</td> <td>    0.575</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>621.229</td> <th>  Durbin-Watson:     </th> <td>   1.939</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20884.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.611</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>17.786</td>  <th>  Cond. No.          </th> <td>    92.0</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.428\n",
       "Model:                            OLS   Adj. R-squared:                  0.425\n",
       "Method:                 Least Squares   F-statistic:                     121.0\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):          5.90e-262\n",
       "Time:                        08:36:45   Log-Likelihood:                -2145.2\n",
       "No. Observations:                2277   AIC:                             4320.\n",
       "Df Residuals:                    2262   BIC:                             4406.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.7278      0.065     26.705      0.000       1.601       1.855\n",
       "Aroused        0.5517      0.048     11.465      0.000       0.457       0.646\n",
       "Creative       0.5517      0.031     17.939      0.000       0.491       0.612\n",
       "Dry            2.2722      0.626      3.629      0.000       1.044       3.500\n",
       "Energetic      0.5412      0.034     15.845      0.000       0.474       0.608\n",
       "Euphoric       0.5400      0.031     17.683      0.000       0.480       0.600\n",
       "Focused        0.5161      0.032     16.031      0.000       0.453       0.579\n",
       "Giggly         0.4525      0.042     10.764      0.000       0.370       0.535\n",
       "Happy          0.5248      0.035     15.106      0.000       0.457       0.593\n",
       "Hungry         0.4509      0.036     12.514      0.000       0.380       0.522\n",
       "Relaxed        0.6743      0.035     19.396      0.000       0.606       0.742\n",
       "Sleepy         0.4967      0.033     14.862      0.000       0.431       0.562\n",
       "Talkative      0.5547      0.038     14.446      0.000       0.479       0.630\n",
       "Tingly         0.4803      0.039     12.395      0.000       0.404       0.556\n",
       "Uplifted       0.5156      0.030     17.043      0.000       0.456       0.575\n",
       "==============================================================================\n",
       "Omnibus:                      621.229   Durbin-Watson:                   1.939\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20884.032\n",
       "Skew:                          -0.611   Prob(JB):                         0.00\n",
       "Kurtosis:                      17.786   Cond. No.                         92.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto (sabores)\n",
    "results = regress1(X,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos realizadas as regressoes, foi observado que o valor de R^2 estava baixo. eliminando as variaveis com valores \"p\" alto, continuou um valor baixo para R^2. Entao, foi retirado da regressao a constante os o resultados estao mostrados a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressao sem a constante\n",
    "def regress(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = datanova1['Rating']\n",
    "x = datanova1[['Tipo', 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted', 'Ammonia', 'Apple', 'Apricot',\n",
    "       'Berry', 'Blue', 'Blueberry', 'Butter', 'Cheese', 'Chemical',\n",
    "       'Chestnut', 'Citrus', 'Coffee', 'Diesel', 'Earthy', 'Flowery', 'Fruit',\n",
    "       'Grape', 'Grapefruit', 'Honey', 'Lavender', 'Lemon', 'Lime', 'Mango',\n",
    "       'Menthol', 'Mint', 'Minty', 'Nutty', 'Orange', 'Peach', 'Pear',\n",
    "       'Pepper', 'Pine', 'Pineapple', 'Plum', 'Pungent', 'Rose', 'Sage',\n",
    "       'Skunk', 'Spicy/Herbal', 'Strawberry', 'Sweet', 'Tar', 'Tea', 'Tobacco',\n",
    "       'Tree', 'Tropical', 'Vanilla', 'Violet', 'Woody']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1355.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:53:56</td>     <th>  Log-Likelihood:    </th> <td> -2416.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4958.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2214</td>      <th>  BIC:               </th> <td>   5319.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    63</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>         <td>    0.0794</td> <td>    0.020</td> <td>    3.960</td> <td> 0.000</td> <td>    0.040</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>      <td>    0.7661</td> <td>    0.057</td> <td>   13.433</td> <td> 0.000</td> <td>    0.654</td> <td>    0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>     <td>    0.7724</td> <td>    0.038</td> <td>   20.287</td> <td> 0.000</td> <td>    0.698</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>          <td>    1.8429</td> <td>    0.386</td> <td>    4.777</td> <td> 0.000</td> <td>    1.086</td> <td>    2.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th>    <td>    0.7460</td> <td>    0.042</td> <td>   17.610</td> <td> 0.000</td> <td>    0.663</td> <td>    0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>     <td>    0.7409</td> <td>    0.039</td> <td>   19.166</td> <td> 0.000</td> <td>    0.665</td> <td>    0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>      <td>    0.7231</td> <td>    0.040</td> <td>   18.110</td> <td> 0.000</td> <td>    0.645</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>       <td>    0.6790</td> <td>    0.050</td> <td>   13.642</td> <td> 0.000</td> <td>    0.581</td> <td>    0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>        <td>    0.7007</td> <td>    0.044</td> <td>   15.917</td> <td> 0.000</td> <td>    0.614</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>       <td>    0.6846</td> <td>    0.044</td> <td>   15.735</td> <td> 0.000</td> <td>    0.599</td> <td>    0.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>        <td>    1.8429</td> <td>    0.386</td> <td>    4.777</td> <td> 0.000</td> <td>    1.086</td> <td>    2.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>      <td>    0.9393</td> <td>    0.044</td> <td>   21.532</td> <td> 0.000</td> <td>    0.854</td> <td>    1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>       <td>    0.6951</td> <td>    0.042</td> <td>   16.631</td> <td> 0.000</td> <td>    0.613</td> <td>    0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th>    <td>    0.7512</td> <td>    0.047</td> <td>   16.094</td> <td> 0.000</td> <td>    0.660</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>       <td>    0.7017</td> <td>    0.046</td> <td>   15.119</td> <td> 0.000</td> <td>    0.611</td> <td>    0.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>     <td>    0.7253</td> <td>    0.038</td> <td>   19.087</td> <td> 0.000</td> <td>    0.651</td> <td>    0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ammonia</th>      <td>    0.2319</td> <td>    0.143</td> <td>    1.627</td> <td> 0.104</td> <td>   -0.048</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apple</th>        <td>    0.0060</td> <td>    0.187</td> <td>    0.032</td> <td> 0.975</td> <td>   -0.360</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Apricot</th>      <td>    0.0762</td> <td>    0.257</td> <td>    0.297</td> <td> 0.766</td> <td>   -0.427</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Berry</th>        <td>    0.2535</td> <td>    0.056</td> <td>    4.531</td> <td> 0.000</td> <td>    0.144</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blue</th>         <td>   -0.1245</td> <td>    0.258</td> <td>   -0.482</td> <td> 0.630</td> <td>   -0.631</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blueberry</th>    <td>    0.2323</td> <td>    0.075</td> <td>    3.115</td> <td> 0.002</td> <td>    0.086</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Butter</th>       <td>    0.1272</td> <td>    0.169</td> <td>    0.751</td> <td> 0.452</td> <td>   -0.205</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cheese</th>       <td>    0.0842</td> <td>    0.105</td> <td>    0.801</td> <td> 0.423</td> <td>   -0.122</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chemical</th>     <td>    0.2505</td> <td>    0.126</td> <td>    1.995</td> <td> 0.046</td> <td>    0.004</td> <td>    0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chestnut</th>     <td>    0.1359</td> <td>    0.298</td> <td>    0.457</td> <td> 0.648</td> <td>   -0.448</td> <td>    0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Citrus</th>       <td>    0.2053</td> <td>    0.052</td> <td>    3.964</td> <td> 0.000</td> <td>    0.104</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Coffee</th>       <td>    0.3686</td> <td>    0.153</td> <td>    2.412</td> <td> 0.016</td> <td>    0.069</td> <td>    0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel</th>       <td>    0.2147</td> <td>    0.060</td> <td>    3.581</td> <td> 0.000</td> <td>    0.097</td> <td>    0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Earthy</th>       <td>    0.1784</td> <td>    0.046</td> <td>    3.837</td> <td> 0.000</td> <td>    0.087</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flowery</th>      <td>    0.2635</td> <td>    0.058</td> <td>    4.544</td> <td> 0.000</td> <td>    0.150</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit</th>        <td>    0.0786</td> <td>    0.067</td> <td>    1.173</td> <td> 0.241</td> <td>   -0.053</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grape</th>        <td>    0.2288</td> <td>    0.076</td> <td>    3.002</td> <td> 0.003</td> <td>    0.079</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grapefruit</th>   <td>    0.1636</td> <td>    0.123</td> <td>    1.325</td> <td> 0.185</td> <td>   -0.079</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Honey</th>        <td>    0.2863</td> <td>    0.135</td> <td>    2.129</td> <td> 0.033</td> <td>    0.023</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lavender</th>     <td>    0.2152</td> <td>    0.126</td> <td>    1.713</td> <td> 0.087</td> <td>   -0.031</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lemon</th>        <td>    0.2233</td> <td>    0.065</td> <td>    3.422</td> <td> 0.001</td> <td>    0.095</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lime</th>         <td>    0.2782</td> <td>    0.107</td> <td>    2.608</td> <td> 0.009</td> <td>    0.069</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mango</th>        <td>    0.1829</td> <td>    0.132</td> <td>    1.386</td> <td> 0.166</td> <td>   -0.076</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Menthol</th>      <td>    0.4150</td> <td>    0.157</td> <td>    2.638</td> <td> 0.008</td> <td>    0.106</td> <td>    0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mint</th>         <td>    0.2022</td> <td>    0.176</td> <td>    1.150</td> <td> 0.250</td> <td>   -0.142</td> <td>    0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minty</th>        <td>    0.3721</td> <td>    0.120</td> <td>    3.106</td> <td> 0.002</td> <td>    0.137</td> <td>    0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nutty</th>        <td>    0.2135</td> <td>    0.148</td> <td>    1.440</td> <td> 0.150</td> <td>   -0.077</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orange</th>       <td>    0.2136</td> <td>    0.093</td> <td>    2.297</td> <td> 0.022</td> <td>    0.031</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>        <td>    0.7887</td> <td>    0.295</td> <td>    2.677</td> <td> 0.007</td> <td>    0.211</td> <td>    1.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pear</th>         <td>    0.2450</td> <td>    0.418</td> <td>    0.586</td> <td> 0.558</td> <td>   -0.575</td> <td>    1.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pepper</th>       <td>    0.2728</td> <td>    0.101</td> <td>    2.692</td> <td> 0.007</td> <td>    0.074</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pine</th>         <td>    0.2392</td> <td>    0.057</td> <td>    4.164</td> <td> 0.000</td> <td>    0.127</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pineapple</th>    <td>    0.2114</td> <td>    0.121</td> <td>    1.754</td> <td> 0.080</td> <td>   -0.025</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Plum</th>         <td>    0.0037</td> <td>    0.510</td> <td>    0.007</td> <td> 0.994</td> <td>   -0.997</td> <td>    1.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pungent</th>      <td>    0.2074</td> <td>    0.052</td> <td>    4.003</td> <td> 0.000</td> <td>    0.106</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rose</th>         <td>    0.1154</td> <td>    0.185</td> <td>    0.625</td> <td> 0.532</td> <td>   -0.247</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sage</th>         <td>    0.2027</td> <td>    0.121</td> <td>    1.669</td> <td> 0.095</td> <td>   -0.036</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skunk</th>        <td>    0.2331</td> <td>    0.068</td> <td>    3.453</td> <td> 0.001</td> <td>    0.101</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spicy/Herbal</th> <td>    0.2516</td> <td>    0.061</td> <td>    4.138</td> <td> 0.000</td> <td>    0.132</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Strawberry</th>   <td>    0.1722</td> <td>    0.112</td> <td>    1.542</td> <td> 0.123</td> <td>   -0.047</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sweet</th>        <td>    0.2237</td> <td>    0.046</td> <td>    4.896</td> <td> 0.000</td> <td>    0.134</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tar</th>          <td>    0.3273</td> <td>    0.273</td> <td>    1.199</td> <td> 0.231</td> <td>   -0.208</td> <td>    0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea</th>          <td>    0.0861</td> <td>    0.177</td> <td>    0.486</td> <td> 0.627</td> <td>   -0.262</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tobacco</th>      <td>   -0.0175</td> <td>    0.256</td> <td>   -0.068</td> <td> 0.946</td> <td>   -0.520</td> <td>    0.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tree</th>         <td>    0.0786</td> <td>    0.067</td> <td>    1.173</td> <td> 0.241</td> <td>   -0.053</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tropical</th>     <td>    0.2089</td> <td>    0.071</td> <td>    2.922</td> <td> 0.004</td> <td>    0.069</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vanilla</th>      <td>    0.1887</td> <td>    0.134</td> <td>    1.410</td> <td> 0.159</td> <td>   -0.074</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violet</th>       <td>    0.2193</td> <td>    0.276</td> <td>    0.796</td> <td> 0.426</td> <td>   -0.321</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Woody</th>        <td>    0.1182</td> <td>    0.060</td> <td>    1.968</td> <td> 0.049</td> <td>    0.000</td> <td>    0.236</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1415.144</td> <th>  Durbin-Watson:     </th> <td>   1.966</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>46498.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.395</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>24.614</td>  <th>  Cond. No.          </th> <td>1.39e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.975\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     1355.\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        08:53:56   Log-Likelihood:                -2416.1\n",
       "No. Observations:                2277   AIC:                             4958.\n",
       "Df Residuals:                    2214   BIC:                             5319.\n",
       "Df Model:                          63                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Tipo             0.0794      0.020      3.960      0.000       0.040       0.119\n",
       "Aroused          0.7661      0.057     13.433      0.000       0.654       0.878\n",
       "Creative         0.7724      0.038     20.287      0.000       0.698       0.847\n",
       "Dry              1.8429      0.386      4.777      0.000       1.086       2.599\n",
       "Energetic        0.7460      0.042     17.610      0.000       0.663       0.829\n",
       "Euphoric         0.7409      0.039     19.166      0.000       0.665       0.817\n",
       "Focused          0.7231      0.040     18.110      0.000       0.645       0.801\n",
       "Giggly           0.6790      0.050     13.642      0.000       0.581       0.777\n",
       "Happy            0.7007      0.044     15.917      0.000       0.614       0.787\n",
       "Hungry           0.6846      0.044     15.735      0.000       0.599       0.770\n",
       "Mouth            1.8429      0.386      4.777      0.000       1.086       2.599\n",
       "Relaxed          0.9393      0.044     21.532      0.000       0.854       1.025\n",
       "Sleepy           0.6951      0.042     16.631      0.000       0.613       0.777\n",
       "Talkative        0.7512      0.047     16.094      0.000       0.660       0.843\n",
       "Tingly           0.7017      0.046     15.119      0.000       0.611       0.793\n",
       "Uplifted         0.7253      0.038     19.087      0.000       0.651       0.800\n",
       "Ammonia          0.2319      0.143      1.627      0.104      -0.048       0.512\n",
       "Apple            0.0060      0.187      0.032      0.975      -0.360       0.372\n",
       "Apricot          0.0762      0.257      0.297      0.766      -0.427       0.579\n",
       "Berry            0.2535      0.056      4.531      0.000       0.144       0.363\n",
       "Blue            -0.1245      0.258     -0.482      0.630      -0.631       0.382\n",
       "Blueberry        0.2323      0.075      3.115      0.002       0.086       0.378\n",
       "Butter           0.1272      0.169      0.751      0.452      -0.205       0.459\n",
       "Cheese           0.0842      0.105      0.801      0.423      -0.122       0.290\n",
       "Chemical         0.2505      0.126      1.995      0.046       0.004       0.497\n",
       "Chestnut         0.1359      0.298      0.457      0.648      -0.448       0.719\n",
       "Citrus           0.2053      0.052      3.964      0.000       0.104       0.307\n",
       "Coffee           0.3686      0.153      2.412      0.016       0.069       0.668\n",
       "Diesel           0.2147      0.060      3.581      0.000       0.097       0.332\n",
       "Earthy           0.1784      0.046      3.837      0.000       0.087       0.270\n",
       "Flowery          0.2635      0.058      4.544      0.000       0.150       0.377\n",
       "Fruit            0.0786      0.067      1.173      0.241      -0.053       0.210\n",
       "Grape            0.2288      0.076      3.002      0.003       0.079       0.378\n",
       "Grapefruit       0.1636      0.123      1.325      0.185      -0.079       0.406\n",
       "Honey            0.2863      0.135      2.129      0.033       0.023       0.550\n",
       "Lavender         0.2152      0.126      1.713      0.087      -0.031       0.462\n",
       "Lemon            0.2233      0.065      3.422      0.001       0.095       0.351\n",
       "Lime             0.2782      0.107      2.608      0.009       0.069       0.487\n",
       "Mango            0.1829      0.132      1.386      0.166      -0.076       0.442\n",
       "Menthol          0.4150      0.157      2.638      0.008       0.106       0.723\n",
       "Mint             0.2022      0.176      1.150      0.250      -0.142       0.547\n",
       "Minty            0.3721      0.120      3.106      0.002       0.137       0.607\n",
       "Nutty            0.2135      0.148      1.440      0.150      -0.077       0.504\n",
       "Orange           0.2136      0.093      2.297      0.022       0.031       0.396\n",
       "Peach            0.7887      0.295      2.677      0.007       0.211       1.367\n",
       "Pear             0.2450      0.418      0.586      0.558      -0.575       1.065\n",
       "Pepper           0.2728      0.101      2.692      0.007       0.074       0.471\n",
       "Pine             0.2392      0.057      4.164      0.000       0.127       0.352\n",
       "Pineapple        0.2114      0.121      1.754      0.080      -0.025       0.448\n",
       "Plum             0.0037      0.510      0.007      0.994      -0.997       1.004\n",
       "Pungent          0.2074      0.052      4.003      0.000       0.106       0.309\n",
       "Rose             0.1154      0.185      0.625      0.532      -0.247       0.477\n",
       "Sage             0.2027      0.121      1.669      0.095      -0.036       0.441\n",
       "Skunk            0.2331      0.068      3.453      0.001       0.101       0.365\n",
       "Spicy/Herbal     0.2516      0.061      4.138      0.000       0.132       0.371\n",
       "Strawberry       0.1722      0.112      1.542      0.123      -0.047       0.391\n",
       "Sweet            0.2237      0.046      4.896      0.000       0.134       0.313\n",
       "Tar              0.3273      0.273      1.199      0.231      -0.208       0.863\n",
       "Tea              0.0861      0.177      0.486      0.627      -0.262       0.434\n",
       "Tobacco         -0.0175      0.256     -0.068      0.946      -0.520       0.485\n",
       "Tree             0.0786      0.067      1.173      0.241      -0.053       0.210\n",
       "Tropical         0.2089      0.071      2.922      0.004       0.069       0.349\n",
       "Vanilla          0.1887      0.134      1.410      0.159      -0.074       0.451\n",
       "Violet           0.2193      0.276      0.796      0.426      -0.321       0.760\n",
       "Woody            0.1182      0.060      1.968      0.049       0.000       0.236\n",
       "==============================================================================\n",
       "Omnibus:                     1415.144   Durbin-Watson:                   1.966\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46498.494\n",
       "Skew:                           2.395   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.614   Cond. No.                     1.39e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.62e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = regress(x,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna \"tipo\" foi retirada, pois observamos que para os 3 diferentes tipos hibrida, sativa, indica o coeficiente era o mesmo, por isso usamos como se o \"tipo\" fosse sempre 1 no np.dot ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = datanova1[[\n",
    "        'Tipo','Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted',  'Peach']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5301.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:37:13</td>     <th>  Log-Likelihood:    </th> <td> -2446.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2277</td>      <th>  AIC:               </th> <td>   4926.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2261</td>      <th>  BIC:               </th> <td>   5017.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tipo</th>      <td>    0.0800</td> <td>    0.020</td> <td>    4.047</td> <td> 0.000</td> <td>    0.041</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Aroused</th>   <td>    0.8890</td> <td>    0.053</td> <td>   16.771</td> <td> 0.000</td> <td>    0.785</td> <td>    0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Creative</th>  <td>    0.8924</td> <td>    0.032</td> <td>   28.025</td> <td> 0.000</td> <td>    0.830</td> <td>    0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dry</th>       <td>    2.0000</td> <td>    0.356</td> <td>    5.624</td> <td> 0.000</td> <td>    1.303</td> <td>    2.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Energetic</th> <td>    0.8690</td> <td>    0.037</td> <td>   23.639</td> <td> 0.000</td> <td>    0.797</td> <td>    0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Euphoric</th>  <td>    0.8669</td> <td>    0.032</td> <td>   27.233</td> <td> 0.000</td> <td>    0.804</td> <td>    0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Focused</th>   <td>    0.8402</td> <td>    0.034</td> <td>   24.668</td> <td> 0.000</td> <td>    0.773</td> <td>    0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Giggly</th>    <td>    0.7922</td> <td>    0.046</td> <td>   17.336</td> <td> 0.000</td> <td>    0.703</td> <td>    0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Happy</th>     <td>    0.8304</td> <td>    0.037</td> <td>   22.167</td> <td> 0.000</td> <td>    0.757</td> <td>    0.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hungry</th>    <td>    0.7902</td> <td>    0.038</td> <td>   20.565</td> <td> 0.000</td> <td>    0.715</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mouth</th>     <td>    2.0000</td> <td>    0.356</td> <td>    5.624</td> <td> 0.000</td> <td>    1.303</td> <td>    2.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Relaxed</th>   <td>    1.0807</td> <td>    0.036</td> <td>   30.101</td> <td> 0.000</td> <td>    1.010</td> <td>    1.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sleepy</th>    <td>    0.8061</td> <td>    0.036</td> <td>   22.392</td> <td> 0.000</td> <td>    0.735</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Talkative</th> <td>    0.8814</td> <td>    0.042</td> <td>   21.220</td> <td> 0.000</td> <td>    0.800</td> <td>    0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tingly</th>    <td>    0.8150</td> <td>    0.042</td> <td>   19.486</td> <td> 0.000</td> <td>    0.733</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Uplifted</th>  <td>    0.8443</td> <td>    0.031</td> <td>   26.836</td> <td> 0.000</td> <td>    0.783</td> <td>    0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Peach</th>     <td>    0.6085</td> <td>    0.292</td> <td>    2.087</td> <td> 0.037</td> <td>    0.037</td> <td>    1.180</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1383.759</td> <th>  Durbin-Watson:     </th> <td>   1.970</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>48420.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.295</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>25.120</td>  <th>  Cond. No.          </th> <td>8.95e+16</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.974\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     5301.\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        08:37:13   Log-Likelihood:                -2446.9\n",
       "No. Observations:                2277   AIC:                             4926.\n",
       "Df Residuals:                    2261   BIC:                             5017.\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Tipo           0.0800      0.020      4.047      0.000       0.041       0.119\n",
       "Aroused        0.8890      0.053     16.771      0.000       0.785       0.993\n",
       "Creative       0.8924      0.032     28.025      0.000       0.830       0.955\n",
       "Dry            2.0000      0.356      5.624      0.000       1.303       2.697\n",
       "Energetic      0.8690      0.037     23.639      0.000       0.797       0.941\n",
       "Euphoric       0.8669      0.032     27.233      0.000       0.804       0.929\n",
       "Focused        0.8402      0.034     24.668      0.000       0.773       0.907\n",
       "Giggly         0.7922      0.046     17.336      0.000       0.703       0.882\n",
       "Happy          0.8304      0.037     22.167      0.000       0.757       0.904\n",
       "Hungry         0.7902      0.038     20.565      0.000       0.715       0.866\n",
       "Mouth          2.0000      0.356      5.624      0.000       1.303       2.697\n",
       "Relaxed        1.0807      0.036     30.101      0.000       1.010       1.151\n",
       "Sleepy         0.8061      0.036     22.392      0.000       0.735       0.877\n",
       "Talkative      0.8814      0.042     21.220      0.000       0.800       0.963\n",
       "Tingly         0.8150      0.042     19.486      0.000       0.733       0.897\n",
       "Uplifted       0.8443      0.031     26.836      0.000       0.783       0.906\n",
       "Peach          0.6085      0.292      2.087      0.037       0.037       1.180\n",
       "==============================================================================\n",
       "Omnibus:                     1383.759   Durbin-Watson:                   1.970\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            48420.841\n",
       "Skew:                           2.295   Prob(JB):                         0.00\n",
       "Kurtosis:                      25.120   Cond. No.                     8.95e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.2e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando variaveis com p>|t| alto\n",
    "results = regress(xx,Y)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos a retirada dos valores de \"p\" alto, ficamos com 15 variaveis, as quais estao citadas a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo         0.079422\n",
       "Aroused      0.766127\n",
       "Creative     0.772433\n",
       "Dry          1.842857\n",
       "Energetic    0.746014\n",
       "Euphoric     0.740885\n",
       "Focused      0.723124\n",
       "Giggly       0.678967\n",
       "Happy        0.700669\n",
       "Hungry       0.684633\n",
       "Mouth        1.842857\n",
       "Relaxed      0.939290\n",
       "Sleepy       0.695147\n",
       "Talkative    0.751195\n",
       "Tingly       0.701655\n",
       "Uplifted     0.725271\n",
       "dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variaveis = results.params[[ 'Tipo','Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']]\n",
    "Variaveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui foi usando o np.dot para conseguirmos prever nota esperada, dependendo das variaveis escolhidas. (Essa parte do teste ainda não esta completa, pretendemos formatar a apresentação com espaços para Input de cada característica na fabricação da maconha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8806845238216656"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Variaveis, np.array([1,0,0,0,0,1,0,0,1,0,0,1,1,0,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ao rodar o programa a seguir, pode-se consultar qual seria a nota de uma strain a partir de 5 efeitos escolhidos pelo usuario. A nota vai de 0 a 5, sendo 5 uma qualidade boa e 0 uma ruim.  O programa funciona da seguinte maneira, os efeitos vao aparecendo e o usuario escolhe 1 para os efeitos desejados ou 0 para os indesejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aroused - 1\n",
      "Creative - 1\n",
      "Dry - 0\n",
      "Energetic - 1\n",
      "Euphoric - 1\n",
      "Focused - 1\n",
      "Giggly - 0\n",
      "Happy - 0\n",
      "Hungry - 0\n",
      "Mouth - 0\n",
      "Relaxed - 0\n",
      "Sleepy - 0\n",
      "Talkative - 0\n",
      "Tingly - 0\n",
      "Uplifted - 0\n",
      "Os efeitos que você escolheu deixam a sua strain com uma nota aproximadamente igual a 3.83\n"
     ]
    }
   ],
   "source": [
    "lista = [ 'Aroused', 'Creative', 'Dry', 'Energetic', 'Euphoric',\n",
    "       'Focused', 'Giggly', 'Happy', 'Hungry', 'Mouth', 'Relaxed', 'Sleepy',\n",
    "       'Talkative', 'Tingly', 'Uplifted']\n",
    "lista_final = [1,]\n",
    "i=1\n",
    "while i <= 15:\n",
    "    for e in lista:\n",
    "        ef = int(input(\"{} - \".format(e)))\n",
    "        if ef > 1:\n",
    "            print(\"Digite 1 para efeito desejado ou 0 para indesejado \")\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        if sum(lista_final)== 6 and ef == 1:\n",
    "            print('Você ja escolheu os 5 efeitos')\n",
    "            ef = int(input(\"{} - \".format(e)))\n",
    "        lista_final.append(ef)\n",
    "        i+=1\n",
    "    \n",
    "nota_final = np.dot(Variaveis, lista_final)\n",
    "print('Os efeitos que você escolheu deixam a sua strain com uma nota aproximadamente igual a {:.2f}'.format(nota_final))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c1964a071a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatanova1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py\u001b[0m in \u001b[0;36mprobplot\u001b[0;34m(x, sparams, dist, fit, plot, rvalue)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_perform_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# perform a linear least squares fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msterrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py\u001b[0m in \u001b[0;36mlinregress\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# average sum of squares:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mssxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssxym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssyxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mr_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssxym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mr_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssxm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mssym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "probplot(datanova1, dist='norm', plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
